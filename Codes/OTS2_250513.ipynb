{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from tkinter import Tk, filedialog\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import cdist\n",
    "from lmfit import Model\n",
    "import tifffile\n",
    "from skimage import morphology\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colocalization Analysis and Time-Delay Pipeline\n",
    "\n",
    "## Function Call Hierarchy\n",
    "\n",
    "```text\n",
    "run_full_analysis\n",
    "├── main_data_loading\n",
    "│   ├── load_tracks_xml\n",
    "│   └── tracks_to_dataframe\n",
    "├── run_main_filtering\n",
    "│   ├── compute_first_and_last_appearance\n",
    "│   ├── apply_roi_foi_filter\n",
    "│   ├── apply_already_activated_filter\n",
    "│   ├── apply_revived_filter_matlab\n",
    "│   └── apply_overlapping_filter_matlab\n",
    "├── find_colocalized_pairs_matlab\n",
    "│   └── internal_loop  (pairwise distance calculation)\n",
    "├── main_time_delay_fitting\n",
    "│   ├── fit_time_delay_exp1decay\n",
    "│   │   ├── exp1decay_func\n",
    "│   │   └── compute_r_squared\n",
    "│   ├── plot_time_delay_exp1decay\n",
    "│   └── plot_time_delay_exp1decay_inverse_x\n",
    "├── main_analysis_after_dark_pairs\n",
    "│   ├── load_multistack\n",
    "│   ├── analyze_dark_pairs\n",
    "│   │   └── visualize_dark_pairs\n",
    "│   └── main_time_delay_fitting  ← 재호출\n",
    "└── making_mark_start\n",
    "\n",
    "marker_df_2\n",
    "├── patch generation per frame\n",
    "└── merging patch tables\n",
    "\n",
    "plot_patch_df_grid_grouped\n",
    "├── render_single_row\n",
    "└── center_channel_table\n",
    "\n",
    "combine_figures_to_one_subplot\n",
    "└── render_to_numpy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Variable Summary\n",
    "\n",
    "| Variable          | Description                                                              |\n",
    "|-------------------|--------------------------------------------------------------------------|\n",
    "| `df_g`, `df_r`    | Raw green/red tracking data from XML                                     |\n",
    "| `df_g_ol`, `df_r_ol` | Final filtered green/red tracks (revived/overlap removed)           |\n",
    "| `primary_pair_df` | Colocalized green-red spot pairs (DataFrame)                            |\n",
    "| `df_mark`         | Spot pair table with first-frame info per track                         |\n",
    "| `multistack`      | 4D numpy array of the TIFF image (x, y, t, channel)                      |\n",
    "| `patch_df`        | Marker visualization patches with RICM overlay                          |\n",
    "| `settings`        | Dictionary of all analysis parameters                                   |\n",
    "| `metadata`        | Metadata from TrackMate XML (units, interval, etc.)                     |\n",
    "\n",
    "---\n",
    "\n",
    "## Execution Flow (`run_full_analysis()`)\n",
    "\n",
    "```text\n",
    "1. Load XML + TIFF via GUI: main_data_loading()\n",
    "2. Filter green/red tracks: run_main_filtering()\n",
    "   - ROI, FOI, activation, revived, overlapping\n",
    "3. Colocalize tracks: find_colocalized_pairs_matlab()\n",
    "4. Time delay fitting: main_time_delay_fitting()\n",
    "5. Segment RICM dark regions: main_analysis_after_dark_pairs()\n",
    "   - Includes fitting for \"on dark\" and \"not on dark\" separately\n",
    "6. Extract start time of tracks: making_mark_start()\n",
    "7. (Optional) Extract visualization patch: marker_df_2()\n",
    "8. (Optional) Visualize: plot_patch_df_grid_grouped() → combine_figures_to_one_subplot()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "df_mark = run_full_analysis(criInter=0.6, criIntra=0.5, criOverlap=2.5, criBlink=2)\n",
    "\n",
    "# Optional visualization\n",
    "patch_df = marker_df_2(multistack, df_mark, df_mark)\n",
    "figs = plot_patch_df_grid_grouped(patch_df)\n",
    "combine_figures_to_one_subplot(figs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Output Preview\n",
    "\n",
    "- `df_mark`: Initial frame (`first_g_T`, `first_r_T`) of each paired track\n",
    "- `patch_df`: List of visual patches for each track with color-coded marker (red/yellow/blue)\n",
    "- Time-delay histogram plot (τ, R²)\n",
    "- Overlay visualization of colocalized tracks on RICM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_settings(criInter=0.6, criIntra=0.5, criOverlap=2.5, criBlink=2):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of default analysis parameters used for\n",
    "    dual-channel spot pairing, time-delay fitting, and RICM overlay evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    criInter : float\n",
    "        Inter-channel distance threshold (e.g., for colocalization in microns).\n",
    "\n",
    "    criIntra : float\n",
    "        Intra-channel displacement tolerance (e.g., drift between frames).\n",
    "\n",
    "    criOverlap : float\n",
    "        Minimum number of overlapping frames to consider a valid colocalized pair.\n",
    "\n",
    "    criBlink : int\n",
    "        Maximum number of allowed missing frames (blinks) within a track.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    settings : dict\n",
    "        Dictionary containing all analysis parameters for downstream processing.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"path0\": r\"D:/\",                   # Root directory for input/output files\n",
    "        \"fTest\": False,                    # Flag for test mode or debug run\n",
    "        \"RICMchannel\": 1,                  # Index of RICM (reflection interference) image channel\n",
    "        \"nChan\": 3,                        # Total number of image channels (e.g., 3 for RGB)\n",
    "        \"frameToOverlay\": 40,             # Frame index used for RICM/image overlay visualization\n",
    "        \"TimeDelayFitting\": 15,           # Time window (frames) for delay fitting around colocalization\n",
    "        \"imgsize\": 800,                   # Width/height of square image (pixels)\n",
    "        \"edge\": 100,                      # Margin pixels to exclude from edge effects\n",
    "        \"frameCnt\": 200,                  # Total number of frames in the movie stack\n",
    "        \"roi\": [100, 700, 100, 700],      # Region of interest: [xmin, xmax, ymin, ymax]\n",
    "        \"criInter\": criInter,            # Max distance for inter-channel spot pairing\n",
    "        \"criIntra\": criIntra,            # Max movement allowed within channel\n",
    "        \"criOverlap\": criOverlap,        # Min overlap duration for a valid pair (in frames)\n",
    "        \"criBlink\": criBlink,            # Max number of frames that can be missed (blinking tolerance)\n",
    "        \"interval\": 15,                  # Time interval between frames (seconds or arbitrary unit)\n",
    "        \"lateralOffset\": [0.0, 0.0],     # Optional lateral shift (X, Y) between channels\n",
    "        \"criLengthMin1\": 2,              # Min track length in channel 1 (green)\n",
    "        \"criLengthMin2\": 3,              # Min track length in channel 2 (red)\n",
    "        \"timeHistEdges\": np.arange(-35.5, 36.5, 1),  # Histogram bin edges for time delay distribution\n",
    "    }\n",
    "\n",
    "def load_tracks_xml(filepath):\n",
    "    \"\"\"\n",
    "    Load tracking data from a TrackMate-generated XML file.\n",
    "\n",
    "    This function parses an XML file produced by the TrackMate plugin in Fiji/ImageJ.\n",
    "    It interprets each <particle> as a single track and extracts the sequence of\n",
    "    spot detections (detection elements with t, x, y, z attributes) while preserving order.\n",
    "\n",
    "    Additionally, metadata such as spatial units, time units, and frame interval\n",
    "    are extracted from the XML root attributes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str or Path\n",
    "        Path to the TrackMate XML file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tracks : list of pandas.DataFrame\n",
    "        A list of track DataFrames. Each DataFrame contains:\n",
    "        - T : time/frame index (float)\n",
    "        - X : x-coordinate (float)\n",
    "        - Y : y-coordinate (float)\n",
    "        - Z : z-coordinate (float)\n",
    "\n",
    "    metadata : dict\n",
    "        Dictionary containing global metadata from the XML file:\n",
    "        - spaceUnits      : unit of spatial measurement (e.g., \"micron\", \"pixels\")\n",
    "        - timeUnits       : unit of time measurement (e.g., \"seconds\", \"frames\")\n",
    "        - frameInterval   : interval between frames\n",
    "        - date            : timestamp when the XML was generated\n",
    "        - source          : source or software that generated the file\n",
    "    \"\"\"\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract basic metadata from the root <TrackMate> tag\n",
    "    metadata = {\n",
    "        \"spaceUnits\": root.attrib.get(\"spaceUnits\", \"pixels\"),\n",
    "        \"timeUnits\": root.attrib.get(\"timeUnits\", \"frames\"),\n",
    "        \"frameInterval\": float(root.attrib.get(\"frameInterval\", 1.0)),\n",
    "        \"date\": root.attrib.get(\"generationDateTime\", \"\"),\n",
    "        \"source\": root.attrib.get(\"from\", \"\")\n",
    "    }\n",
    "\n",
    "    tracks = []\n",
    "\n",
    "    # Each <particle> element corresponds to a single track\n",
    "    particles = root.findall(\".//particle\")\n",
    "\n",
    "    for particle in particles:\n",
    "        detections = particle.findall(\".//detection\")\n",
    "        t_list = []\n",
    "        for d in detections:\n",
    "            t = float(d.attrib.get(\"t\", 0))\n",
    "            x = float(d.attrib.get(\"x\", 0))\n",
    "            y = float(d.attrib.get(\"y\", 0))\n",
    "            z = float(d.attrib.get(\"z\", 0))\n",
    "            t_list.append([t, x, y, z])\n",
    "\n",
    "        if len(t_list) > 0:\n",
    "            tracks.append(pd.DataFrame(t_list, columns=[\"T\", \"X\", \"Y\", \"Z\"]))\n",
    "\n",
    "    return tracks, metadata\n",
    "\n",
    "def tracks_to_dataframe(tracks):\n",
    "    \"\"\"\n",
    "    Convert a list of per-track DataFrames into a single unified DataFrame.\n",
    "\n",
    "    Each input DataFrame represents a track and contains columns:\n",
    "        - T : time point (frame index)\n",
    "        - X : x-coordinate\n",
    "        - Y : y-coordinate\n",
    "        - Z : z-coordinate (optional; ignored in this output)\n",
    "\n",
    "    The function assigns a unique track ID to each track and\n",
    "    compiles all timepoints into a flat DataFrame suitable for filtering,\n",
    "    visualization, or machine learning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tracks : list of pandas.DataFrame\n",
    "        List of DataFrames where each DataFrame corresponds to a single track.\n",
    "        Each DataFrame must have columns: [\"T\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Combined DataFrame with columns:\n",
    "        - track_id : integer index assigned to each track\n",
    "        - T        : rounded time/frame index (int)\n",
    "        - X        : x-coordinate (float)\n",
    "        - Y        : y-coordinate (float)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for track_id, df in enumerate(tracks):\n",
    "        for _, row in df.iterrows():\n",
    "            rows.append((track_id, round(row[\"T\"]), row[\"X\"], row[\"Y\"]))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"track_id\", \"T\", \"X\", \"Y\"])\n",
    "\n",
    "def compute_first_and_last_appearance(df, min_length, method=\"median\"):\n",
    "    \"\"\"\n",
    "    Compute the first and last appearance of each track and its spatial center.\n",
    "\n",
    "    This function filters out short tracks based on a minimum length requirement,\n",
    "    and for each remaining track, calculates:\n",
    "    - First frame (T_first)\n",
    "    - Last frame (T_last)\n",
    "    - Spatial center (X_center, Y_center) using mean or median\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        A DataFrame with columns: [\"track_id\", \"T\", \"X\", \"Y\"]\n",
    "        Each row represents a spot detection at frame T for a given track.\n",
    "\n",
    "    min_length : int\n",
    "        Minimum number of timepoints (frames) required for a track to be retained.\n",
    "\n",
    "    method : str, optional, default=\"median\"\n",
    "        Aggregation method to compute spatial center of the track:\n",
    "        - \"median\" : compute median of X and Y\n",
    "        - \"mean\"   : compute mean of X and Y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_fl : pandas.DataFrame\n",
    "        DataFrame with one row per track, including:\n",
    "        - track_id   : ID of the track\n",
    "        - T_first    : first frame the track appears\n",
    "        - T_last     : last frame the track appears\n",
    "        - X_center   : average or median X position\n",
    "        - Y_center   : average or median Y position\n",
    "    \"\"\"\n",
    "    # Count how many timepoints each track has\n",
    "    counts = df.groupby(\"track_id\")[\"T\"].count()\n",
    "\n",
    "    # Keep only tracks that meet the minimum length requirement\n",
    "    valid_tracks = counts[counts >= min_length].index\n",
    "    df_valid = df[df[\"track_id\"].isin(valid_tracks)].copy()\n",
    "\n",
    "    # Choose aggregation function for X and Y\n",
    "    agg_func = {\"T\": [\"min\", \"max\"]}\n",
    "    if method == \"mean\":\n",
    "        agg_func[\"X\"] = \"mean\"\n",
    "        agg_func[\"Y\"] = \"mean\"\n",
    "    else:\n",
    "        agg_func[\"X\"] = \"median\"\n",
    "        agg_func[\"Y\"] = \"median\"\n",
    "\n",
    "    # Aggregate data per track\n",
    "    df_fl = df_valid.groupby(\"track_id\").agg(agg_func)\n",
    "\n",
    "    # Flatten multi-level columns\n",
    "    df_fl.columns = [\"T_first\", \"T_last\", \"X_center\", \"Y_center\"]\n",
    "    df_fl = df_fl.reset_index()\n",
    "\n",
    "    return df_fl\n",
    "\n",
    "def apply_roi_foi_filter(df_fl: pd.DataFrame,\n",
    "                         t_min: int,\n",
    "                         t_max: int,\n",
    "                         roi: list[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply spatial (ROI) and temporal (FOI) filters to a DataFrame of tracks\n",
    "    based on first appearance time and center position.\n",
    "\n",
    "    This function mimics the logic of MATLAB-style for-loop filtering, and keeps\n",
    "    only those tracks whose first timepoint falls within a time range (FOI),\n",
    "    and whose center position falls within a rectangular region (ROI).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_fl : pandas.DataFrame\n",
    "        A DataFrame containing one row per track, with at least the following columns:\n",
    "        - \"T_first\" : first frame where the track appears\n",
    "        - \"X_center\": X coordinate of the track's spatial center\n",
    "        - \"Y_center\": Y coordinate of the track's spatial center\n",
    "\n",
    "    t_min : int\n",
    "        Minimum allowed frame index (inclusive) for the first appearance.\n",
    "\n",
    "    t_max : int\n",
    "        Maximum allowed frame index (inclusive) for the first appearance.\n",
    "\n",
    "    roi : list of int [x_min, x_max, y_min, y_max]\n",
    "        Spatial region of interest (ROI) defined as:\n",
    "        - roi[0]: minimum X\n",
    "        - roi[1]: maximum X\n",
    "        - roi[2]: minimum Y\n",
    "        - roi[3]: maximum Y\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A filtered DataFrame containing only the tracks within both\n",
    "        the specified temporal and spatial ranges.\n",
    "    \"\"\"\n",
    "    cond = (\n",
    "        (df_fl[\"T_first\"] >= t_min) & (df_fl[\"T_first\"] <= t_max) &\n",
    "        (df_fl[\"X_center\"].between(roi[0], roi[1])) &\n",
    "        (df_fl[\"Y_center\"].between(roi[2], roi[3]))\n",
    "    )\n",
    "    return df_fl[cond].reset_index(drop=True)\n",
    "\n",
    "def apply_already_activated_filter(df_g: pd.DataFrame,\n",
    "                                   df_r: pd.DataFrame,\n",
    "                                   interval: int):\n",
    "    \"\"\"\n",
    "    Filter out tracks that appear too early (before activation window).\n",
    "\n",
    "    This function mimics the MATLAB for-loop logic used to exclude tracks\n",
    "    that are already active before the start of the observation or delay window.\n",
    "    This helps ensure only new or \"freshly activated\" tracks are included.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_g : pandas.DataFrame\n",
    "        DataFrame for green-channel tracks.\n",
    "        Must contain a \"T_first\" column indicating first appearance frame.\n",
    "\n",
    "    df_r : pandas.DataFrame\n",
    "        DataFrame for red-channel tracks.\n",
    "        Must also contain a \"T_first\" column.\n",
    "\n",
    "    interval : int\n",
    "        Minimum required start frame for green-channel tracks.\n",
    "        Tracks with `T_first < interval` are removed from df_g.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_g_filt : pandas.DataFrame\n",
    "        Filtered green-channel DataFrame where T_first >= interval.\n",
    "\n",
    "    df_r_filt : pandas.DataFrame\n",
    "        Filtered red-channel DataFrame where T_first >= 1.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Green tracks are filtered with a stricter threshold (`interval`)\n",
    "      to avoid early-appearing events in time-delay pairing.\n",
    "    - Red tracks are only filtered to remove those starting at T=0.\n",
    "    \"\"\"\n",
    "    df_g_filt = df_g[df_g[\"T_first\"] >= interval].reset_index(drop=True)\n",
    "    df_r_filt = df_r[df_r[\"T_first\"] >= 1].reset_index(drop=True)\n",
    "    return df_g_filt, df_r_filt\n",
    "\n",
    "def apply_revived_filter_matlab(df_first: pd.DataFrame, cri_intra: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove revived (redundant) spots using MATLAB-style rules.\n",
    "\n",
    "    This function eliminates spatially redundant tracks based on pairwise distances,\n",
    "    using a logic that mimics the original MATLAB implementation:\n",
    "\n",
    "        • If two points are within 'cri_intra' distance,\n",
    "        • The one with later (or same) T_first is discarded,\n",
    "        • If T_first is equal, the one with the larger row index is removed.\n",
    "\n",
    "    This preserves only the earliest-appearing track within a neighborhood,\n",
    "    using triangular index logic (lower triangle) to ensure stability and prevent double removal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_first : pandas.DataFrame\n",
    "        Input DataFrame with one row per track.\n",
    "        Must contain:\n",
    "        - \"T_first\": first appearance frame\n",
    "        - \"X_center\", \"Y_center\": spatial coordinates of the track\n",
    "\n",
    "    cri_intra : float\n",
    "        Maximum distance within which two tracks are considered redundant.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered DataFrame with revived tracks removed. Index is reset.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Uses pairwise distance matrix (cdist) for full comparison (O(N^2)).\n",
    "    - Applies \"lower triangular\" logic to ensure unique pair comparisons.\n",
    "    - Follows MATLAB rule: if two points are too close,\n",
    "        drop the one that is later or has higher index if simultaneous.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step ①: Extract coordinates and appearance time as NumPy arrays\n",
    "    coords = df_first[[\"X_center\", \"Y_center\"]].to_numpy(float)\n",
    "    times = df_first[\"T_first\"].to_numpy()\n",
    "\n",
    "    # Step ②: Compute full pairwise distance matrix (N × N)\n",
    "    dist_mat = cdist(coords, coords)\n",
    "\n",
    "    # Step ③: Create a mask of all (i, j) pairs with distance < cri_intra (but i ≠ j)\n",
    "    mask = (dist_mat < cri_intra) & (dist_mat > 0)\n",
    "\n",
    "    # Step ④: Apply lower triangular logic (i > j) to avoid duplicate comparisons\n",
    "    tri_mask = np.tril(mask, k=-1)\n",
    "\n",
    "    # Step ⑤: Get all (i, j) index pairs that satisfy the lower triangle condition\n",
    "    i_idx, j_idx = np.where(tri_mask)\n",
    "\n",
    "    # Step ⑥: For each (i, j) pair, drop i if its T_first >= T_first of j\n",
    "    later_or_equal = times[i_idx] - times[j_idx] >= 0\n",
    "    rows_to_drop = i_idx[later_or_equal]\n",
    "\n",
    "    # Step ⑦: Create a boolean mask for rows to keep\n",
    "    keep_mask = np.ones(len(df_first), dtype=bool)\n",
    "    keep_mask[rows_to_drop] = False\n",
    "\n",
    "    return df_first.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "def apply_overlapping_filter_matlab(df: pd.DataFrame, cri_overlap: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove all overlapping spots based on spatial proximity using MATLAB-style logic.\n",
    "\n",
    "    This function identifies all pairs of spots (rows) that are closer than a \n",
    "    given radius (`cri_overlap`), and removes both from the dataset. This is useful \n",
    "    in scenarios where any spatially ambiguous or overlapping detections should be excluded.\n",
    "\n",
    "    The logic replicates the MATLAB approach:\n",
    "        • If two points are within cri_overlap distance (and not the same point),\n",
    "        • Both points are discarded,\n",
    "        • Only one direction of the pair (i > j) is checked to avoid redundancy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame of spot or track centers.\n",
    "        Must contain:\n",
    "        - \"X_center\": x-coordinate of the center\n",
    "        - \"Y_center\": y-coordinate of the center\n",
    "\n",
    "    cri_overlap : float\n",
    "        Maximum distance threshold under which two spots are considered overlapping.\n",
    "        Any pair with distance < cri_overlap will be removed (both rows).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered DataFrame excluding all overlapping points.\n",
    "        Index is reset after filtering.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - All (i, j) pairs within cri_overlap distance are detected.\n",
    "    - Both i and j are removed if i > j (lower triangle) to avoid duplicate checks.\n",
    "    - This is stricter than 'revived' filtering, where only one point is removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step ①: Extract coordinate array\n",
    "    coords = df[[\"X_center\", \"Y_center\"]].to_numpy(float)\n",
    "\n",
    "    # Step ②: Compute full pairwise distance matrix (N x N)\n",
    "    dist_mat = cdist(coords, coords)\n",
    "\n",
    "    # Step ③: Create mask for close pairs (not self)\n",
    "    mask = (dist_mat < cri_overlap) & (dist_mat > 0)\n",
    "\n",
    "    # Step ④: Apply lower-triangular mask to avoid double-counting\n",
    "    tri_mask = np.tril(mask, k=-1)\n",
    "\n",
    "    # Step ⑤: Get all (i, j) index pairs that should be removed\n",
    "    i_idx, j_idx = np.where(tri_mask)\n",
    "\n",
    "    # Step ⑥: Mark both i and j for removal\n",
    "    rows_to_drop = np.unique(np.concatenate([i_idx, j_idx]))\n",
    "\n",
    "    # Step ⑦: Create boolean mask to retain non-overlapping rows\n",
    "    keep_mask = np.ones(len(df), dtype=bool)\n",
    "    keep_mask[rows_to_drop] = False\n",
    "\n",
    "    return df.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "def find_colocalized_pairs_matlab(df1: pd.DataFrame,\n",
    "                                   df2: pd.DataFrame,\n",
    "                                   criInter: float,\n",
    "                                   valid_rows: np.ndarray | None = None\n",
    "                                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Find colocalized spot pairs using MATLAB-style for-loop logic.\n",
    "\n",
    "    This function mimics the MATLAB colocalization loop exactly:\n",
    "        • For each green spot (df1), compute Euclidean distance to all red spots (df2)\n",
    "        • If the minimum distance is less than criInter, save the pair\n",
    "        • One red spot can be matched to multiple green spots (duplicates allowed)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : pandas.DataFrame\n",
    "        DataFrame of reference spots (e.g., green channel).\n",
    "        Must include columns:\n",
    "        - \"track_id\"\n",
    "        - \"T_first\"\n",
    "        - \"X_center\"\n",
    "        - \"Y_center\"\n",
    "\n",
    "    df2 : pandas.DataFrame\n",
    "        DataFrame of comparison spots (e.g., red channel).\n",
    "        Same required columns as df1.\n",
    "\n",
    "    criInter : float\n",
    "        Maximum distance (in pixels or microns) allowed to consider a spot pair colocalized.\n",
    "\n",
    "    valid_rows : np.ndarray of bool, optional\n",
    "        Boolean array (same length as df1) indicating which rows are eligible for matching.\n",
    "        If None, all rows in df1 are considered valid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame of matched colocalized pairs with the following columns:\n",
    "        - time_delay : T_green - T_red\n",
    "        - distance   : Euclidean distance between spot centers\n",
    "        - ref_id     : track_id from df1 (green)\n",
    "        - ref_T      : T_first from df1\n",
    "        - ref_X      : X_center from df1\n",
    "        - ref_Y      : Y_center from df1\n",
    "        - cmp_id     : track_id from df2 (red)\n",
    "        - cmp_T      : T_first from df2\n",
    "        - cmp_X      : X_center from df2\n",
    "        - cmp_Y      : Y_center from df2\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract coordinate and time arrays\n",
    "    coords1 = df1[[\"X_center\", \"Y_center\"]].to_numpy(float)\n",
    "    coords2 = df2[[\"X_center\", \"Y_center\"]].to_numpy(float)\n",
    "    times1  = df1[\"T_first\"].to_numpy()\n",
    "    times2  = df2[\"T_first\"].to_numpy()\n",
    "\n",
    "    # Initialize mask for valid rows if not provided\n",
    "    if valid_rows is None:\n",
    "        valid_rows = np.ones(len(df1), dtype=bool)\n",
    "    else:\n",
    "        valid_rows = np.asarray(valid_rows, dtype=bool)\n",
    "\n",
    "    pair_rec = []\n",
    "\n",
    "    # MATLAB-style loop: for i = find(valid_rows)'\n",
    "    for i in np.where(valid_rows)[0]:\n",
    "        # Compute distance to all spots in df2\n",
    "        diff = coords2 - coords1[i]           # Shape: (N2, 2)\n",
    "        distlist = np.sqrt(np.sum(diff**2, axis=1))\n",
    "\n",
    "        # Find the nearest red spot\n",
    "        id = int(distlist.argmin())\n",
    "        minDist = float(distlist[id])\n",
    "\n",
    "        # If below colocalization threshold, record the pair\n",
    "        if minDist < criInter:\n",
    "            pair_rec.append([\n",
    "                float(times1[i] - times2[id]),              # Time delay\n",
    "                minDist,                                     # Distance\n",
    "                int(df1.iloc[i][\"track_id\"]),               # Reference (green) track ID\n",
    "                float(times1[i]), float(coords1[i, 0]), float(coords1[i, 1]),\n",
    "                int(df2.iloc[id][\"track_id\"]),              # Comparison (red) track ID\n",
    "                float(times2[id]), float(coords2[id, 0]), float(coords2[id, 1]),\n",
    "            ])\n",
    "\n",
    "    cols = [\n",
    "        \"time_delay\", \"distance\",\n",
    "        \"ref_id\", \"ref_T\", \"ref_X\", \"ref_Y\",\n",
    "        \"cmp_id\", \"cmp_T\", \"cmp_X\", \"cmp_Y\"\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(pair_rec, columns=cols)\n",
    "\n",
    "def exp1decay_func(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Single exponential decay function.\n",
    "\n",
    "    This model is commonly used to describe time-dependent decay processes,\n",
    "    such as fluorescence bleaching, signal attenuation, or molecular unbinding.\n",
    "\n",
    "    Mathematical form:\n",
    "        f(x) = (a - c) * exp(-x / b) + c\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        Input (usually time) values at which to evaluate the function.\n",
    "\n",
    "    a : float\n",
    "        Initial value at time zero, i.e., f(0) = a.\n",
    "\n",
    "    b : float\n",
    "        Time constant (decay rate); controls how quickly the function decays.\n",
    "\n",
    "    c : float\n",
    "        Asymptotic value; the baseline that the function approaches as x → ∞.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array-like\n",
    "        Output values of the exponential decay function evaluated at x.\n",
    "    \"\"\"\n",
    "    return (a - c) * np.exp(-x / b) + c\n",
    "\n",
    "def compute_r_squared(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the coefficient of determination (R² score) between true and predicted values.\n",
    "\n",
    "    R² measures the proportion of variance in the dependent variable (y_true)\n",
    "    that is predictable from the independent variable(s) (via y_pred).\n",
    "    \n",
    "    It is defined as:\n",
    "        R² = 1 - (SS_res / SS_tot)\n",
    "    where:\n",
    "        SS_res = Σ (y_true - y_pred)²   → residual sum of squares\n",
    "        SS_tot = Σ (y_true - mean(y_true))²   → total sum of squares\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        Ground truth (observed) values.\n",
    "\n",
    "    y_pred : array-like\n",
    "        Predicted values from the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_squared : float\n",
    "        R² score. Ranges from -∞ to 1.0\n",
    "        - 1.0 means perfect prediction\n",
    "        - 0.0 means model predicts as poorly as just using the mean\n",
    "        - Negative values imply the model performs worse than the mean\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If the variance in y_true is zero (i.e., all values are the same), R² is undefined.\n",
    "      In that case, the function returns np.nan.\n",
    "    \"\"\"\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)  # Residual sum of squares\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # Total sum of squares\n",
    "\n",
    "    if np.allclose(ss_tot, 0):\n",
    "        return np.nan  # R² undefined when y_true has no variance\n",
    "\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def fit_time_delay_exp1decay(xdata, ydata, frameInterval=1.0, min_points=6):\n",
    "    \"\"\"\n",
    "    Robust fitting of a time-delay histogram using a single exponential decay model.\n",
    "\n",
    "    This function fits the provided (x, y) data using the model:\n",
    "        y = (a - c) * exp(-x / b) + c\n",
    "    which describes a single-phase exponential decay, often used in time delay\n",
    "    or unbinding analyses in biological imaging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xdata : array-like\n",
    "        The x-axis values (e.g., time delay in frame units).\n",
    "\n",
    "    ydata : array-like\n",
    "        The observed data points (e.g., counts or normalized histogram values).\n",
    "\n",
    "    frameInterval : float, default=1.0\n",
    "        Time duration of one frame (in seconds). Used to convert the decay constant\n",
    "        from frames to seconds.\n",
    "\n",
    "    min_points : int, default=6\n",
    "        Minimum number of data points required to attempt fitting.\n",
    "        If fewer points are given, fitting is skipped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : lmfit.model.ModelResult or None\n",
    "        The fitted model result object from `lmfit`, or None if fitting fails.\n",
    "\n",
    "    tau : float or None\n",
    "        Estimated decay constant τ (in seconds), converted from frames.\n",
    "        τ = b * frameInterval.\n",
    "\n",
    "    r_squared : float or None\n",
    "        Coefficient of determination (R²) indicating fit quality.\n",
    "        Returns None if fitting fails.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The initial guess for the decay constant (b) is estimated as the index\n",
    "      where the signal drops to ~50% of its initial value.\n",
    "    - If fitting fails, the function prints an error message and returns (None, None, None).\n",
    "    \"\"\"\n",
    "\n",
    "    xdata = np.asarray(xdata)\n",
    "    ydata = np.asarray(ydata)\n",
    "\n",
    "    if len(xdata) < min_points or len(ydata) < min_points:\n",
    "        print(f\"Insufficient data: xData={xdata}, yData={ydata}\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        y0 = ydata[0]\n",
    "        # Estimate where the signal drops to half for initial guess of b\n",
    "        tmp_idx = np.argmin(np.abs(ydata[1:] - 0.5 * y0)) + 1\n",
    "\n",
    "        model = Model(exp1decay_func)\n",
    "        params = model.make_params(a=y0, b=tmp_idx + 1, c=0)\n",
    "\n",
    "        result = model.fit(ydata, params, x=xdata)\n",
    "\n",
    "        # Convert decay constant from frames to seconds\n",
    "        tau = result.params[\"b\"].value * frameInterval\n",
    "\n",
    "        # Evaluate fitted model and compute R²\n",
    "        y_pred = result.eval(x=xdata)\n",
    "        r_squared = compute_r_squared(ydata, y_pred)\n",
    "\n",
    "        return result, tau, r_squared\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Fitting failed:\", str(e))\n",
    "        return None, None, None\n",
    "\n",
    "def plot_time_delay_exp1decay(bin_centers, hist_vals, xData, yData, fit_result, time_delay, r_squared, time_unit=\"sec\"):\n",
    "    \"\"\"\n",
    "    Visualizes the fitting results of a time-delay histogram using exponential decay.\n",
    "\n",
    "    This function generates a plot showing the time-delay histogram along with the fitted exponential decay curve.\n",
    "    The plot includes information about the decay constant (τ) and the coefficient of determination (R²) if available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bin_centers : array-like\n",
    "        The center points of the histogram bins, representing the time delay values (in frames).\n",
    "\n",
    "    hist_vals : array-like\n",
    "        The histogram values corresponding to the bin_centers, representing the frequency/count of data in each time delay bin.\n",
    "\n",
    "    xData : array-like\n",
    "        The x-values (time delay values) for fitting, typically the same as bin_centers but used for the fitting procedure.\n",
    "\n",
    "    yData : array-like\n",
    "        The y-values (histogram counts) for fitting, typically the same as hist_vals but used for fitting.\n",
    "\n",
    "    fit_result : lmfit.model.ModelResult or None\n",
    "        The fitted result object from `lmfit`, containing the parameters and values of the exponential decay fit.\n",
    "        If no fitting was performed, this should be `None`.\n",
    "\n",
    "    time_delay : float\n",
    "        The time constant (τ) estimated from the exponential decay fit, in the units specified by `time_unit`.\n",
    "\n",
    "    r_squared : float or None\n",
    "        The coefficient of determination (R²) for the fit, indicating the goodness of fit. If fitting fails, this may be `None`.\n",
    "\n",
    "    time_unit : str, default=\"sec\"\n",
    "        The unit of time for the time constant (τ), such as \"sec\" or \"ms\".\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The histogram is plotted as bars, with the fitted exponential decay curve overlaid.\n",
    "    - The plot includes a vertical line at x=0 to indicate the origin for time delays.\n",
    "    - The title of the plot displays the R² value if fitting is successful, otherwise it shows \"R²=N/A\".\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(bin_centers, hist_vals, width=1.0, alpha=0.5, label=\"histogram\")\n",
    "    plt.axvline(0, linestyle=\"--\", color=\"blue\", label=\"x=0\")\n",
    "\n",
    "    if fit_result is not None:\n",
    "        x_fit = np.linspace(min(xData), max(xData), 100)\n",
    "        y_fit = fit_result.eval(x=x_fit)\n",
    "        plt.plot(x_fit, y_fit, \"r-\", label=f\"Exp Fit (τ={time_delay:.2f} {time_unit}, R²={r_squared:.3f})\")\n",
    "\n",
    "    plt.xlabel(\"Time delay (frame)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    if r_squared is not None:\n",
    "        plt.title(f\"Exp Fit (R²={r_squared:.3f})\")\n",
    "    else:\n",
    "        plt.title(\"Exp Fit (R²=N/A)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_delay_exp1decay_inverse_x(bin_centers, hist_vals, xData, yData, fit_result, time_delay, r_squared, time_unit=\"sec\"):\n",
    "    \"\"\"\n",
    "    Plot the time-delay histogram and exponential fit using inverse x-axis transformation (1/x).\n",
    "\n",
    "    This visualization helps highlight short time delays and behaviors near x = 0,\n",
    "    often used when events occurring very quickly are of particular interest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bin_centers : array-like\n",
    "        Center values of the time-delay histogram bins (x-axis, in frame units).\n",
    "\n",
    "    hist_vals : array-like\n",
    "        Histogram counts corresponding to bin_centers.\n",
    "\n",
    "    xData : array-like\n",
    "        x values used for fitting (same units as bin_centers).\n",
    "\n",
    "    yData : array-like\n",
    "        y values used for fitting (same units as hist_vals).\n",
    "\n",
    "    fit_result : lmfit.model.ModelResult or None\n",
    "        Result of fitting using an exponential decay model. If None, no fit curve is shown.\n",
    "\n",
    "    time_delay : float\n",
    "        Fitted decay time constant τ, to be shown in the legend (in units of time_unit).\n",
    "\n",
    "    r_squared : float or None\n",
    "        R² value indicating goodness of fit. If None, this is omitted from the title.\n",
    "\n",
    "    time_unit : str, default=\"sec\"\n",
    "        Unit for time constant τ (e.g., 'sec', 'ms').\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - All x=0 values are excluded to avoid division-by-zero errors.\n",
    "    - The fit curve is plotted against 1/x values, and the original histogram is also transformed accordingly.\n",
    "    - A vertical dashed line at x=0 is retained for visual reference.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Exclude x=0 to avoid divide-by-zero\n",
    "    nonzero_mask = bin_centers != 0\n",
    "    inv_bin_centers = 1 / bin_centers[nonzero_mask]\n",
    "    inv_hist_vals = hist_vals[nonzero_mask]\n",
    "\n",
    "    # Plot histogram on inverted x-axis\n",
    "    plt.bar(inv_bin_centers, inv_hist_vals, width=0.05, alpha=0.5, label=\"histogram\")\n",
    "    plt.axvline(0, linestyle=\"--\", color=\"blue\", label=\"x=0\")\n",
    "\n",
    "    # Plot the fitted exponential curve, if available\n",
    "    if fit_result is not None:\n",
    "        x_fit = np.linspace(min(xData), max(xData), 100)\n",
    "        x_fit = x_fit[x_fit != 0]  # Exclude zero\n",
    "        inv_x_fit = 1 / x_fit\n",
    "        y_fit = fit_result.eval(x=x_fit)\n",
    "        plt.plot(inv_x_fit, y_fit, \"r-\", label=f\"Exp Fit (τ={time_delay:.2f} {time_unit}, R²={r_squared:.3f})\")\n",
    "\n",
    "    # Axis labels and title\n",
    "    plt.xlabel(\"1 / Time delay (1/frame)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    if r_squared is not None:\n",
    "        plt.title(f\"Exp Fit (R²={r_squared:.3f})\")\n",
    "    else:\n",
    "        plt.title(\"Exp Fit (R²=N/A)\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_multistack(imagefile, nChan=None):\n",
    "    \"\"\"\n",
    "    Load a 4D TIFF image stack and reorder axes to (width, height, time, channel).\n",
    "\n",
    "    This function assumes the TIFF is stored in the order:\n",
    "        (frames, channels, height, width)\n",
    "    as is common in BioFormats exports or ImageJ multichannel exports.\n",
    "\n",
    "    The returned array will be reordered to match MATLAB's convention:\n",
    "        (nx, ny, frameCnt, nChan)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imagefile : str\n",
    "        Path to the TIFF file.\n",
    "\n",
    "    nChan : int or None, optional\n",
    "        If specified, manually enforce the number of channels (e.g., 3 or 4).\n",
    "        If None, the number of channels is inferred from the file.\n",
    "        If the specified nChan does not match the file's channels, a warning is printed and the file's value is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    multistack : np.ndarray\n",
    "        A 4D NumPy array with shape (nx, ny, frameCnt, nChan),\n",
    "        corresponding to (width, height, time, channels).\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Load the TIFF file as a 4D array\n",
    "    stack0 = tifffile.imread(imagefile)\n",
    "\n",
    "    if stack0.ndim != 4:\n",
    "        raise ValueError(\n",
    "            f\"Expected a 4D TIFF (frames, channels, height, width). \"\n",
    "            f\"Got shape {stack0.shape}.\"\n",
    "        )\n",
    "\n",
    "    # Extract shape dimensions\n",
    "    frames, channels, ny, nx = stack0.shape\n",
    "    print(f\"Loaded TIFF shape: (frames={frames}, channels={channels}, \"\n",
    "          f\"height={ny}, width={nx})\")\n",
    "    print(f\"stack0 dtype: {stack0.dtype}\")\n",
    "\n",
    "    # Step 2: Determine number of channels\n",
    "    if nChan is None:\n",
    "        nChan = channels\n",
    "    if nChan != channels:\n",
    "        print(f\"Warning: The file has {channels} channels, but nChan={nChan} was given. \"\n",
    "              f\"Using {channels} from the file.\")\n",
    "        nChan = channels\n",
    "\n",
    "    # Step 3: Reorder dimensions to match MATLAB convention\n",
    "    # From: (frames, channels, height, width)\n",
    "    # To:   (width, height, frames, channels)\n",
    "    multistack = stack0.transpose(3, 2, 0, 1)\n",
    "\n",
    "    # Final check\n",
    "    print(f\"Final multistack shape: {multistack.shape} \"\n",
    "          \"(nx, ny, frames, channels)\")\n",
    "\n",
    "    return multistack\n",
    "\n",
    "def analyze_dark_pairs(multistack, pair, settings, frameToShow=100, visualize=True):\n",
    "    \"\"\"\n",
    "    Identify colocalized spot pairs that fall into 'dark' regions of the RICM channel.\n",
    "\n",
    "    Steps performed:\n",
    "        1. Extract the RICM channel and create binary masks of dark regions via morphological filtering.\n",
    "        2. Determine whether both green and red spots in each pair fall into dark areas.\n",
    "        3. Optionally visualize the detected regions and filtered results.\n",
    "        4. Return filtered DataFrames or arrays of 'on-dark' and 'not-on-dark' spot pairs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    multistack : np.ndarray\n",
    "        4D image stack with shape (nx, ny, frameCnt, nChan).\n",
    "\n",
    "    pair : pd.DataFrame or np.ndarray\n",
    "        Colocalized spot pairs. If a DataFrame is passed, the function returns DataFrames as well.\n",
    "        Expected columns/order: ['time_delay', 'distance', ..., 'g_T', 'g_X', 'g_Y', ..., 'r_T', 'r_X', 'r_Y'].\n",
    "\n",
    "    settings : dict\n",
    "        Analysis settings, must include:\n",
    "        - \"RICMchannel\" : 1-based index of the RICM channel in the stack\n",
    "        - \"frameInterval\" : (optional) time per frame in seconds\n",
    "\n",
    "    frameToShow : int, default=100\n",
    "        Frame index to visualize when `visualize=True`.\n",
    "\n",
    "    visualize : bool, default=True\n",
    "        Whether to display a visualization of dark regions and spot locations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pairOnDark : pd.DataFrame or np.ndarray\n",
    "        Pairs where both the green and red spot fall within dark regions (±1 frame).\n",
    "\n",
    "    pairNotOnDark : pd.DataFrame or np.ndarray\n",
    "        Pairs that do not meet the dark region criteria.\n",
    "\n",
    "    maskStack : np.ndarray (bool)\n",
    "        Binary mask stack of dark regions. Shape: (nx, ny, frameCnt)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Dark regions are defined using Top-hat and Otsu thresholding followed by morphological filtering.\n",
    "    - Each spot (green or red) is checked for presence within dark areas in frame ±1 of its appearance.\n",
    "    - This is designed for RICM images, where dark regions typically indicate tight cell-surface contact.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 0) Convert DataFrame to NumPy array if needed\n",
    "    columns = None\n",
    "    if isinstance(pair, pd.DataFrame):\n",
    "        columns = pair.columns\n",
    "        pair = pair.to_numpy()\n",
    "\n",
    "    nx, ny, frameCnt, nChan = multistack.shape\n",
    "    RICMchannel = settings[\"RICMchannel\"] - 1  # Convert to 0-based index\n",
    "    frameInterval = settings.get(\"frameInterval\", 1.0)\n",
    "\n",
    "    # 1) Extract RICM channel → shape: (nx, ny, frameCnt)\n",
    "    ricmStack = multistack[:, :, :, RICMchannel]\n",
    "\n",
    "    # 2) Generate binary masks of dark regions\n",
    "    maskStack = np.zeros((nx, ny, frameCnt), dtype=bool)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (21, 21))\n",
    "\n",
    "    for fr in range(frameCnt):\n",
    "        # Normalize frame and invert contrast\n",
    "        img = cv2.normalize(ricmStack[:, :, fr], None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        inv = cv2.bitwise_not(img)\n",
    "        top_hat = cv2.morphologyEx(inv, cv2.MORPH_TOPHAT, kernel)\n",
    "        th_comp = cv2.bitwise_not(top_hat)\n",
    "\n",
    "        # Binary threshold + postprocessing\n",
    "        _, bw = cv2.threshold(th_comp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        bw = cv2.bitwise_not(bw)\n",
    "        bw = cv2.medianBlur(bw, 3)\n",
    "        bw = cv2.dilate(bw, kernel)\n",
    "        fill = morphology.remove_small_holes(bw > 0, area_threshold=1000)\n",
    "        maskStack[:, :, fr] = fill\n",
    "\n",
    "    # 3) Check if both green and red spots fall on dark regions (±1 frame)\n",
    "    pairCnt = pair.shape[0]\n",
    "    onDark = np.zeros(pairCnt, dtype=bool)\n",
    "\n",
    "    for i in range(pairCnt):\n",
    "        fr_g = int(round(pair[i, 3]))\n",
    "        xg   = int(round(pair[i, 4]))\n",
    "        yg   = int(round(pair[i, 5]))\n",
    "        fr_r = int(round(pair[i, 7]))\n",
    "        xr   = int(round(pair[i, 8]))\n",
    "        yr   = int(round(pair[i, 9]))\n",
    "\n",
    "        def in_mask(x, y, f):\n",
    "            if x < 0 or x >= nx or y < 0 or y >= ny or f < 0 or f >= frameCnt:\n",
    "                return False\n",
    "            return maskStack[x, y, f]\n",
    "\n",
    "        g_dark = any(in_mask(xg, yg, fr_g + dt) for dt in [-1, 0, 1])\n",
    "        r_dark = any(in_mask(xr, yr, fr_r + dt) for dt in [-1, 0, 1])\n",
    "        if g_dark and r_dark:\n",
    "            onDark[i] = True\n",
    "\n",
    "    pairOnDark_np = pair[onDark]\n",
    "    pairNotOnDark_np = pair[~onDark]\n",
    "\n",
    "    # 4) Convert back to DataFrame if original input was DataFrame\n",
    "    if columns is not None:\n",
    "        pairOnDark = pd.DataFrame(pairOnDark_np, columns=columns)\n",
    "        pairNotOnDark = pd.DataFrame(pairNotOnDark_np, columns=columns)\n",
    "    else:\n",
    "        pairOnDark = pairOnDark_np\n",
    "        pairNotOnDark = pairNotOnDark_np\n",
    "\n",
    "    # Optional check for debugging: consistency between mask and onDark result\n",
    "    for i in range(pairCnt):\n",
    "        y, x, frame = int(pair[i, 5]), int(pair[i, 4]), int(pair[i, 3])  # Note: y, x order\n",
    "        if maskStack[x, y, frame] != onDark[i]:\n",
    "            print(f\"Mismatch at index {i}: maskStack={maskStack[x, y, frame]}, onDark={onDark[i]}\")\n",
    "\n",
    "    # 5) Visualization\n",
    "    if visualize:\n",
    "        visualize_dark_pairs(ricmStack, maskStack, pair, onDark, frameToShow)\n",
    "\n",
    "    return pairOnDark, pairNotOnDark, maskStack\n",
    "\n",
    "def visualize_dark_pairs(ricmStack, maskStack, pair, onDark, frameToShow):\n",
    "    \"\"\"\n",
    "    Visualize a specific frame of the RICM image along with its dark region mask\n",
    "    and overlaid spot pair locations.\n",
    "\n",
    "    This visualization helps verify whether detected spot pairs fall within\n",
    "    morphologically defined dark regions, typically corresponding to close\n",
    "    cell-substrate contact zones in RICM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ricmStack : np.ndarray\n",
    "        The extracted RICM image stack with shape (nx, ny, frameCnt).\n",
    "\n",
    "    maskStack : np.ndarray (bool)\n",
    "        The binary mask stack indicating dark regions (same shape as ricmStack).\n",
    "\n",
    "    pair : np.ndarray\n",
    "        Array of colocalized spot pairs. Columns 4 and 5 are assumed to contain\n",
    "        the X and Y coordinates of the green (reference) spot.\n",
    "\n",
    "    onDark : np.ndarray (bool)\n",
    "        Boolean array of same length as `pair` indicating whether each pair\n",
    "        is located on a dark region.\n",
    "\n",
    "    frameToShow : int\n",
    "        Index of the frame to visualize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a 1x3 subplot: [RICM Image, Dark Mask, Overlay]\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # 1) Show the original RICM image\n",
    "    axs[0].imshow(ricmStack[:, :, frameToShow].T, cmap='gray', origin='lower')\n",
    "    axs[0].set_title(f\"RICM Image (Frame {frameToShow})\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # 2) Show the binary dark region mask\n",
    "    axs[1].imshow(maskStack[:, :, frameToShow].T, cmap='binary', origin='lower')\n",
    "    axs[1].set_title(f\"Dark Region Mask (Frame {frameToShow})\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    # 3) Overlay the green spot positions: red = onDark, blue = not onDark\n",
    "    axs[2].imshow(ricmStack[:, :, frameToShow].T, cmap='gray', origin='lower')\n",
    "\n",
    "    axs[2].scatter(pair[onDark, 4], pair[onDark, 5], c='red', s=10, label=\"On Dark\")\n",
    "    axs[2].scatter(pair[~onDark, 4], pair[~onDark, 5], c='blue', s=10, label=\"Not On Dark\")\n",
    "\n",
    "    axs[2].set_title(\"Pairs (Red: On Dark, Blue: Not On Dark)\")\n",
    "    axs[2].axis(\"off\")\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main_data_loading(criInter=0.6, criIntra=0.6, criOverlap=2.5, criBlink=2.0):\n",
    "    \"\"\"\n",
    "    Load the necessary data files for time-delay and co-localization analysis.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Load analysis settings with given filter thresholds.\n",
    "    2. Change working directory to `path0`.\n",
    "    3. Let the user select a TIFF image file for overlay.\n",
    "    4. Automatically detect or prompt the user to load TrackMate XML files for green and red tracks.\n",
    "    5. Parse the XML files and convert to DataFrames.\n",
    "    6. Extract metadata including time interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    criInter : float\n",
    "        Maximum allowed distance between green/red tracks for colocalization.\n",
    "\n",
    "    criIntra : float\n",
    "        Radius threshold for intra-channel duplicate removal.\n",
    "\n",
    "    criOverlap : float\n",
    "        Distance threshold for excluding spatially overlapping tracks.\n",
    "\n",
    "    criBlink : float\n",
    "        Maximum tolerated blinking gap during spot tracking.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_g : pd.DataFrame\n",
    "        DataFrame of green-channel (reference) track detections.\n",
    "\n",
    "    df_r : pd.DataFrame\n",
    "        DataFrame of red-channel (comparison) track detections.\n",
    "\n",
    "    imagefile : str\n",
    "        Full path to the selected TIFF image.\n",
    "\n",
    "    pathImgFile : str\n",
    "        Directory containing the TIFF image.\n",
    "\n",
    "    filenamehead : str\n",
    "        Image filename without extension (used as a base name for finding XMLs).\n",
    "\n",
    "    metadata_g : dict\n",
    "        Metadata parsed from the green-channel XML (includes units, frame interval, etc).\n",
    "\n",
    "    settings : dict\n",
    "        Dictionary of all analysis parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load default analysis settings\n",
    "    settings = get_analysis_settings(criInter, criIntra, criOverlap, criBlink)\n",
    "    path0 = settings[\"path0\"]\n",
    "\n",
    "    # Check if base path exists\n",
    "    if not os.path.exists(path0):\n",
    "        print(f\"Warning: path0 does not exist: {path0}\")\n",
    "    os.chdir(path0)\n",
    "\n",
    "    # Early exit if testing mode is enabled\n",
    "    if settings[\"fTest\"]:\n",
    "        print(\"Skipping data loading due to fTest=True.\")\n",
    "        return None, None, None, None, None, settings\n",
    "\n",
    "    # Let user choose a TIFF image file\n",
    "    Tk().withdraw()\n",
    "    imagefile = filedialog.askopenfilename(\n",
    "        title=\"Open an image file to overlay\",\n",
    "        filetypes=[(\"TIFF files\", \"*.tif\")]\n",
    "    )\n",
    "    if not imagefile:\n",
    "        print(\"No image selected. Abort.\")\n",
    "        return None, None, None, None, None, settings\n",
    "\n",
    "    pathImgFile, imageName = os.path.split(imagefile)\n",
    "    filenamehead, _ = os.path.splitext(imageName)\n",
    "\n",
    "    # Expected XML filenames based on TIFF basename\n",
    "    trjfile1 = os.path.join(pathImgFile, f\"{filenamehead}_g.xml\")\n",
    "    trjfile2 = os.path.join(pathImgFile, f\"{filenamehead}_r.xml\")\n",
    "\n",
    "    # If not found, manually prompt user for XML files\n",
    "    if not (os.path.isfile(trjfile1) and os.path.isfile(trjfile2)):\n",
    "        print(\"Select reference track file (g) & compare track file (r).\")\n",
    "        trjfile1 = filedialog.askopenfilename(\n",
    "            title=\"Choose a reference track file (high force)\",\n",
    "            filetypes=[(\"XML files\", \"*.xml\")])\n",
    "        trjfile2 = filedialog.askopenfilename(\n",
    "            title=\"Choose a track file to be compared (low force)\",\n",
    "            filetypes=[(\"XML files\", \"*.xml\")])\n",
    "        if not trjfile1 or not trjfile2:\n",
    "            print(\"Canceled track file selection.\")\n",
    "            return None, None, None, None, None, settings\n",
    "        pathTracks = os.path.dirname(trjfile1)\n",
    "        os.chdir(pathTracks)\n",
    "    else:\n",
    "        os.chdir(pathImgFile)\n",
    "\n",
    "    # Load XML files\n",
    "    print(\"Loading TrackMate xml files...\")\n",
    "    t0 = time.time()\n",
    "    tracks1, metadata_g = load_tracks_xml(trjfile1)\n",
    "    tracks2, metadata_r = load_tracks_xml(trjfile2)\n",
    "\n",
    "    # Convert track lists to flat DataFrames\n",
    "    df_g = tracks_to_dataframe(tracks1)\n",
    "    df_r = tracks_to_dataframe(tracks2)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"XML load done in {elapsed:.2f}s\")\n",
    "    print(\"Reference (g) tracks:\", df_g[\"track_id\"].nunique())\n",
    "    print(\"Compare (r) tracks:\", df_r[\"track_id\"].nunique())\n",
    "\n",
    "    # Print key metadata\n",
    "    print(\"spaceUnits:\", metadata_g[\"spaceUnits\"])\n",
    "    print(\"timeUnits:\", metadata_g[\"timeUnits\"])\n",
    "    frameInterval = round(metadata_g[\"frameInterval\"], 2)\n",
    "    print(\"frameInterval:\", frameInterval)\n",
    "\n",
    "    return df_g, df_r, imagefile, pathImgFile, filenamehead, metadata_g, settings\n",
    "\n",
    "def run_main_filtering(df_g, df_r, settings):\n",
    "    \"\"\"\n",
    "    Apply a series of spatial and temporal filters to green/red track data.\n",
    "\n",
    "    The filtering steps include:\n",
    "    1. First appearance and duration-based pre-filtering.\n",
    "    2. ROI (Region of Interest) and FOI (Frame of Interest) filtering.\n",
    "    3. Early-activation filtering to remove prematurely appearing tracks.\n",
    "    4. Intra-channel redundancy filtering via \"revived\" spot suppression.\n",
    "    5. Spatial de-duplication via overlapping exclusion.\n",
    "    6. Optional chromatic lateral offset correction (e.g., optical misalignment).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_g : pd.DataFrame\n",
    "        Green channel track detections (columns: track_id, T, X, Y).\n",
    "\n",
    "    df_r : pd.DataFrame\n",
    "        Red channel track detections (columns: track_id, T, X, Y).\n",
    "\n",
    "    settings : dict\n",
    "        Dictionary of filtering thresholds and metadata from `get_analysis_settings()`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_g_ol : pd.DataFrame\n",
    "        Final filtered green-channel track summary (one row per track).\n",
    "\n",
    "    df_r_ol : pd.DataFrame\n",
    "        Final filtered red-channel track summary (one row per track).\n",
    "\n",
    "    df_g_roi : pd.DataFrame\n",
    "        Intermediate green tracks within ROI & FOI, before revived/overlap filtering.\n",
    "\n",
    "    df_r_roi : pd.DataFrame\n",
    "        Intermediate red tracks within ROI & FOI, before revived/overlap filtering.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Compute first and last appearance frame of each track\n",
    "    df_first_g = compute_first_and_last_appearance(df_g, settings[\"criLengthMin1\"], method=\"mean\")\n",
    "    df_first_r = compute_first_and_last_appearance(df_r, settings[\"criLengthMin2\"], method=\"median\")\n",
    "\n",
    "    print(f\"After filtering, df_first_g: {len(df_first_g)} tracks, df_first_r: {len(df_first_r)} tracks\")\n",
    "\n",
    "    # 2. Apply ROI (spatial) and FOI (temporal) filters\n",
    "    t_max = settings[\"frameCnt\"] - settings[\"interval\"]\n",
    "\n",
    "    df_g_roi = apply_roi_foi_filter(df_first_g,\n",
    "                                    settings[\"interval\"], t_max,\n",
    "                                    settings[\"roi\"])\n",
    "    df_r_roi = apply_roi_foi_filter(df_first_r,\n",
    "                                    2, t_max,\n",
    "                                    settings[\"roi\"])\n",
    "\n",
    "    # 3. Remove tracks that appeared too early (based on activation delay)\n",
    "    df_g_1, df_r_1 = apply_already_activated_filter(df_g_roi, df_r_roi, settings[\"interval\"])\n",
    "    \n",
    "    print(f\"After filtering, df_g_1: {len(df_g_1)} tracks, df_r_1: {len(df_r_1)} tracks\")\n",
    "\n",
    "    # 4. Apply revived spot filter to avoid duplicate detections within intra-channel radius\n",
    "    df_g_rev = apply_revived_filter_matlab(df_g_1, settings[\"criIntra\"])\n",
    "    df_r_rev = apply_revived_filter_matlab(df_r_1, settings[\"criIntra\"])\n",
    "\n",
    "    print(f\"After filtering, df_g_rev: {len(df_g_rev)} tracks, df_r_rev: {len(df_r_rev)} tracks\")\n",
    "\n",
    "    # 5. Remove overlapping tracks within each channel\n",
    "    df_g_ol = apply_overlapping_filter_matlab(df_g_rev, settings[\"criOverlap\"])\n",
    "    df_r_ol = apply_overlapping_filter_matlab(df_r_rev, settings[\"criOverlap\"])\n",
    "\n",
    "    # 6. Apply chromatic offset correction (e.g., if red channel is misaligned)\n",
    "    df_r_ol[\"X_center\"] += settings[\"lateralOffset\"][0]\n",
    "    df_r_ol[\"Y_center\"] += settings[\"lateralOffset\"][1]\n",
    "\n",
    "    print(f\"After filtering, df_g_ol: {len(df_g_ol)} tracks, df_r_ol: {len(df_r_ol)} tracks\")\n",
    "\n",
    "    return df_g_ol, df_r_ol, df_g_roi, df_r_roi\n",
    "\n",
    "def main_time_delay_fitting(pair_df: pd.DataFrame,\n",
    "                            metadata: dict,\n",
    "                            settings: dict):\n",
    "    \"\"\"\n",
    "    Perform exponential fitting on time-delay histogram from paired colocalized spots.\n",
    "\n",
    "    This function replicates the MATLAB \"Time Delay Fitting\" block and performs:\n",
    "    1. Histogram construction of time delays (bin width = 1 frame)\n",
    "    2. Exponential decay fitting on bins from frame +1 to +15 (default)\n",
    "    3. Calculation of decay constant (τ) and R² goodness-of-fit\n",
    "    4. Visualization of raw histogram with fitted exponential curve\n",
    "    5. Optional inverse-X axis visualization for alternative insight\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pair_df : pd.DataFrame\n",
    "        DataFrame containing colocalized spot pairs with at least 'ref_T' and 'cmp_T' columns.\n",
    "\n",
    "    metadata : dict\n",
    "        Metadata extracted from XML, including 'frameInterval'.\n",
    "\n",
    "    settings : dict\n",
    "        Dictionary with analysis settings, particularly:\n",
    "        - 'TimeDelayFitting': number of bins to use for exponential fitting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Early exit if DataFrame is empty or malformed\n",
    "    if pair_df.empty or \"time_delay\" not in pair_df.columns:\n",
    "        print(\"pair_df is empty or missing 'time_delay' column.\")\n",
    "        return\n",
    "\n",
    "    # Recalculate time delay explicitly from ref_T and cmp_T (rounded to frame integers)\n",
    "    pair_df[\"time_delay\"] = (\n",
    "        pair_df[\"ref_T\"].round().astype(int) -\n",
    "        pair_df[\"cmp_T\"].round().astype(int)\n",
    "    )\n",
    "\n",
    "    # Histogram edges and bin centers from -35.5 to +35.5, step 1\n",
    "    bin_edges   = np.arange(-35.5, 36.5, 1)        # Edges: include both ends\n",
    "    bin_centers = bin_edges[:-1] + 0.5             # Centers: ..., -0.5, 0.5, ...\n",
    "    hist_vals, _ = np.histogram(pair_df[\"time_delay\"], bins=bin_edges)\n",
    "\n",
    "    # Retrieve frame interval from metadata (default = 1.0 sec)\n",
    "    frameInterval = metadata.get(\"frameInterval\", 1.0)\n",
    "\n",
    "    # Locate index of bin centered at 0\n",
    "    idx0 = np.where(np.isclose(bin_centers, 0))[0][0]\n",
    "\n",
    "    # Number of bins to fit (default = 15 bins to the right of zero)\n",
    "    fit_len = settings.get(\"TimeDelayFitting\", 15)\n",
    "    start_idx = idx0 + 1\n",
    "    end_idx = start_idx + fit_len\n",
    "    if end_idx > len(bin_centers):\n",
    "        end_idx = len(bin_centers)\n",
    "\n",
    "    # Extract fitting range\n",
    "    xData = bin_centers[start_idx:end_idx]\n",
    "    yData = hist_vals[start_idx:end_idx]\n",
    "\n",
    "    # Fit exponential decay model: (a - c) * exp(-x / b) + c\n",
    "    fit_result, tau, r2 = fit_time_delay_exp1decay(\n",
    "        xData, yData, frameInterval, min_points=6\n",
    "    )\n",
    "\n",
    "    # Plot histogram and fitted curve (normal x-axis)\n",
    "    plot_time_delay_exp1decay(\n",
    "        bin_centers, hist_vals, xData, yData,\n",
    "        fit_result, tau, r2, time_unit=\"sec\"\n",
    "    )\n",
    "\n",
    "    # Plot with inverse x-axis (1/x) for visualizing early delays\n",
    "    plot_time_delay_exp1decay_inverse_x(\n",
    "        bin_centers, hist_vals, xData, yData,\n",
    "        fit_result, tau, r2, time_unit=\"sec\"\n",
    "    )\n",
    "\n",
    "def main_analysis_after_dark_pairs(imagefile, pair, metadata, settings):\n",
    "    \"\"\"\n",
    "    Perform post-colocalization analysis by separating pairs based on RICM-derived dark regions.\n",
    "\n",
    "    This function does the following:\n",
    "    1. Load a 4D multi-channel TIFF image (RICM + fluorescence).\n",
    "    2. Segment dark regions in the RICM channel.\n",
    "    3. Classify colocalized pairs as being in 'dark' or 'non-dark' zones.\n",
    "    4. Perform time-delay histogram fitting separately for both categories.\n",
    "    5. Return the image and filtered data for further use.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imagefile : str or Path\n",
    "        Path to the input 4D TIFF image file.\n",
    "\n",
    "    pair : pd.DataFrame\n",
    "        DataFrame of colocalized spot pairs with coordinates and frame information.\n",
    "\n",
    "    metadata : dict\n",
    "        Metadata associated with time units, frame interval, etc.\n",
    "\n",
    "    settings : dict\n",
    "        Analysis configuration including channel indices and thresholds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    multistack : np.ndarray\n",
    "        Loaded image stack in shape (nx, ny, frames, channels).\n",
    "\n",
    "    pairOnDark : pd.DataFrame\n",
    "        Subset of input `pair` that falls within dark regions in RICM.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load multi-channel image stack (shape: nx, ny, T, C)\n",
    "    multistack = load_multistack(imagefile)\n",
    "\n",
    "    # Segment RICM dark regions and classify pairs based on overlap\n",
    "    pairOnDark, pairNotOnDark, maskStack = analyze_dark_pairs(multistack, pair, settings)\n",
    "\n",
    "    # Time delay fitting for pairs on dark region\n",
    "    print(\"pairs on dark\")\n",
    "    main_time_delay_fitting(pairOnDark, metadata, settings)\n",
    "\n",
    "    # Time delay fitting for pairs not on dark region\n",
    "    print(\"pairs not on dark\")\n",
    "    main_time_delay_fitting(pairNotOnDark, metadata, settings)\n",
    "\n",
    "    return multistack, pairOnDark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_mark_start(df_g, df_r, pairOnDark):\n",
    "    \"\"\"\n",
    "    Extract initial timepoints of tracks involved in colocalized dark-region pairs.\n",
    "\n",
    "    For each colocalized pair (from 'pairOnDark'), this function:\n",
    "    - Retrieves the green (ref) and red (cmp) track IDs\n",
    "    - Finds the first frame ('T') where each track appears\n",
    "    - Stores those values for downstream time alignment or visualization\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_g : pd.DataFrame\n",
    "        Flattened DataFrame of green-channel tracks. Must contain 'track_id' and 'T'.\n",
    "\n",
    "    df_r : pd.DataFrame\n",
    "        Flattened DataFrame of red-channel tracks. Must contain 'track_id' and 'T'.\n",
    "\n",
    "    pairOnDark : pd.DataFrame\n",
    "        Filtered colocalized pair DataFrame (typically from dark regions only),\n",
    "        must include 'ref_id', 'ref_X', 'ref_Y', and 'cmp_id'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mark : pd.DataFrame\n",
    "        A new DataFrame with:\n",
    "        - ref_id, ref_X, ref_Y from pairOnDark\n",
    "        - first_g_T: first time point of green track\n",
    "        - first_r_T: first time point of red track\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize output DataFrame with position info\n",
    "    df_mark = pairOnDark[[\"ref_id\", \"ref_X\", \"ref_Y\"]].copy()\n",
    "\n",
    "    # Add columns to store first frame of green and red tracks\n",
    "    df_mark[\"first_T\"] = np.nan  # (optional legacy field, not currently used)\n",
    "    df_mark[\"last_T\"] = np.nan   # (optional legacy field, not currently used)\n",
    "\n",
    "    df_mark[\"first_g_T\"] = np.nan\n",
    "    df_mark[\"first_r_T\"] = np.nan\n",
    "\n",
    "    # Loop over all paired entries\n",
    "    for i in range(len(pairOnDark)):\n",
    "        # Retrieve T values for ref (green) and cmp (red) track_id\n",
    "        g_id = pairOnDark[\"ref_id\"].iloc[i]\n",
    "        r_id = pairOnDark[\"cmp_id\"].iloc[i]\n",
    "\n",
    "        set_g_T = df_g.loc[df_g[\"track_id\"] == g_id, \"T\"]\n",
    "        set_r_T = df_r.loc[df_r[\"track_id\"] == r_id, \"T\"]\n",
    "\n",
    "        # Save the first frame for each track\n",
    "        if not set_g_T.empty:\n",
    "            df_mark.at[i, \"first_g_T\"] = sorted(set_g_T)[0]\n",
    "        if not set_r_T.empty:\n",
    "            df_mark.at[i, \"first_r_T\"] = sorted(set_r_T)[0]\n",
    "\n",
    "    return df_mark\n",
    "\n",
    "def marker_df_2(\n",
    "    multistack,\n",
    "    df_mark_1, df_mark_2,\n",
    "    alpha=0.6,\n",
    "    green_gain=1.0,\n",
    "    red_gain=1.0,\n",
    "    green_contrast=1.0,\n",
    "    red_contrast=1.0,\n",
    "    green_gamma=1.0,\n",
    "    red_gamma=1.0,\n",
    "    use_gamma=False,\n",
    "    marker_radius=5,\n",
    "    radius_px=13,\n",
    "    max_workers=16,\n",
    "    use_combined=True,\n",
    "):\n",
    "    '''\n",
    "    Generate marker patches from multichannel image stack by overlaying green/red signals\n",
    "    onto RICM background. Visual indicators are generated frame-wise for each track ID.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    multistack : np.ndarray\n",
    "        4D image stack (nx, ny, n_frames, n_channels).\n",
    "    df_mark_1, df_mark_2 : pd.DataFrame\n",
    "        DataFrames containing markers with columns: ref_id, ref_X, ref_Y, first_g_T, first_r_T.\n",
    "    alpha : float\n",
    "        Blending ratio between RICM and overlay image.\n",
    "    green_gain, red_gain : float\n",
    "        Gain multipliers for green and red channels.\n",
    "    green_contrast, red_contrast : float\n",
    "        Contrast enhancement factors.\n",
    "    green_gamma, red_gamma : float\n",
    "        Gamma correction values.\n",
    "    use_gamma : bool\n",
    "        Whether to apply gamma correction.\n",
    "    marker_radius : int\n",
    "        Radius of circle marker drawn on the patch.\n",
    "    radius_px : int\n",
    "        Width and height of extracted patch in pixels.\n",
    "    max_workers : int\n",
    "        Number of threads to parallelize frame-wise processing.\n",
    "    use_combined : bool\n",
    "        If True, blend red/green with RICM background; otherwise, channel-specific only.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    patch_df : pd.DataFrame\n",
    "        DataFrame containing original coordinates and patch sequences for each marker.\n",
    "    '''\n",
    "\n",
    "    nx, ny, frameCnt, nChan = multistack.shape\n",
    "    greenchannel = 1\n",
    "    redchannel = 2\n",
    "    RICMchannel = 0\n",
    "\n",
    "    greenStack = multistack[:, :, :, greenchannel].astype(np.float32)\n",
    "    redStack = multistack[:, :, :, redchannel].astype(np.float32)\n",
    "    ricmStack = multistack[:, :, :, RICMchannel]\n",
    "\n",
    "    # Merge both marker lists and remove duplicates\n",
    "    combined_df = pd.concat([df_mark_1, df_mark_2]).drop_duplicates()\n",
    "\n",
    "    # Determine group membership based on marker presence\n",
    "    ids1 = set(df_mark_1[\"ref_id\"])\n",
    "    ids2 = set(df_mark_2[\"ref_id\"])\n",
    "    common_ids = ids1 & ids2\n",
    "    only1_ids = ids1 - ids2\n",
    "    only2_ids = ids2 - ids1\n",
    "\n",
    "    def get_group_type(ref_id):\n",
    "        if ref_id in common_ids:\n",
    "            return \"common\"\n",
    "        elif ref_id in only1_ids:\n",
    "            return \"only1\"\n",
    "        elif ref_id in only2_ids:\n",
    "            return \"only2\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    # Initialize patch_df with group information and an empty patch column\n",
    "    patch_df = combined_df[[\"ref_id\", \"first_g_T\", \"first_r_T\", \"ref_X\", \"ref_Y\"]].copy()\n",
    "    patch_df[\"id_group\"] = patch_df[\"ref_id\"].apply(get_group_type)\n",
    "    patch_df[\"patch\"] = [pd.DataFrame(columns=[\"g_frame\", \"g_image\", \"r_frame\", \"r_image\"]) for _ in range(len(patch_df))]\n",
    "\n",
    "    # Define visual properties for different groups\n",
    "    marker_groups = [\n",
    "        (only2_ids, (0, 255, 0), \"g\"),\n",
    "        (only2_ids, (0, 255, 0), \"r\"),\n",
    "        (only1_ids, (0, 0, 255), \"g\"),\n",
    "        (only1_ids, (0, 0, 255), \"r\"),\n",
    "        (common_ids, (255, 255, 0), \"g\"),\n",
    "        (common_ids, (255, 255, 0), \"r\"),\n",
    "    ]\n",
    "\n",
    "    def process_frame(frameToShow):\n",
    "        # Generate marker patches for a single frame\n",
    "        local_patch_list = [None for _ in range(len(patch_df))]\n",
    "\n",
    "        # Extract individual frame data\n",
    "        ricm = ricmStack[:, :, frameToShow]\n",
    "        green = greenStack[:, :, frameToShow]\n",
    "        red = redStack[:, :, frameToShow]\n",
    "\n",
    "        # Normalize and apply contrast/gamma\n",
    "        green = cv2.normalize(green, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        green *= green_contrast\n",
    "        if use_gamma:\n",
    "            green = 255 * ((green / 255) ** green_gamma)\n",
    "\n",
    "        red = cv2.normalize(red, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        red *= red_contrast\n",
    "        if use_gamma:\n",
    "            red = 255 * ((red / 255) ** red_gamma)\n",
    "\n",
    "        # Convert grayscale RICM to RGB\n",
    "        ricm_norm = cv2.normalize(ricm, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        ricm_rgb = cv2.cvtColor(ricm_norm, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Prepare RGB overlays\n",
    "        green_rgb = np.zeros_like(ricm_rgb, dtype=np.float32)\n",
    "        green_rgb[:, :, 1] = np.clip(green_gain * green, 0, 255)\n",
    "\n",
    "        red_rgb = np.zeros_like(ricm_rgb, dtype=np.float32)\n",
    "        red_rgb[:, :, 0] = np.clip(red_gain * red, 0, 255)\n",
    "\n",
    "        # Combine RICM and overlay images\n",
    "        overlay_rgb = green_rgb + red_rgb\n",
    "        blended = np.clip((1 - alpha) * ricm_rgb + alpha * overlay_rgb, 0, 255)\n",
    "        blended_uint8 = blended.astype(np.uint8)\n",
    "\n",
    "        # Extract patches around each marker\n",
    "        for i, row in patch_df.iterrows():\n",
    "            x = int(round(row[\"ref_X\"]))\n",
    "            y = int(round(row[\"ref_Y\"]))\n",
    "            half = radius_px // 2\n",
    "            r1, r2 = max(x - half, 0), min(x + half + 1, nx)\n",
    "            c1, c2 = max(y - half, 0), min(y + half + 1, ny)\n",
    "\n",
    "            new_rows = []\n",
    "\n",
    "            for ids_set, color, channel in marker_groups:\n",
    "                if row[\"ref_id\"] not in ids_set:\n",
    "                    continue\n",
    "\n",
    "                time_col = f\"first_{channel}_T\"\n",
    "                frame_col = f\"{channel}_frame\"\n",
    "                image_col = f\"{channel}_image\"\n",
    "\n",
    "                if not (row[time_col] - 10 <= frameToShow <= row[time_col] + 10):\n",
    "                    continue\n",
    "\n",
    "                if use_combined:\n",
    "                    base_img = blended_uint8\n",
    "                elif channel == 'g':\n",
    "                    base_img = green_rgb.astype(np.uint8)\n",
    "                else:\n",
    "                    base_img = red_rgb.astype(np.uint8)\n",
    "\n",
    "                patch_img = base_img[r1:r2, c1:c2]\n",
    "                pad_h = radius_px - patch_img.shape[0]\n",
    "                pad_w = radius_px - patch_img.shape[1]\n",
    "                top, bottom = pad_h // 2, pad_h - pad_h // 2\n",
    "                left, right = pad_w // 2, pad_w - pad_w // 2\n",
    "                patch_img = cv2.copyMakeBorder(patch_img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                center = (radius_px // 2, radius_px // 2)\n",
    "\n",
    "                marked_img = patch_img.copy()\n",
    "                cv2.circle(marked_img, center, marker_radius, color, thickness=1)\n",
    "\n",
    "                new_row = {\"g_frame\": None, \"g_image\": None, \"r_frame\": None, \"r_image\": None}\n",
    "                new_row[frame_col] = frameToShow\n",
    "                new_row[image_col] = marked_img\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "            if new_rows:\n",
    "                patch_table = patch_df.at[i, \"patch\"]\n",
    "                patch_table = pd.concat([patch_table, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "                local_patch_list[i] = patch_table\n",
    "\n",
    "        return local_patch_list\n",
    "\n",
    "    # Process all frames in parallel\n",
    "    all_patch_tables = [None for _ in range(len(patch_df))]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for frame_result in tqdm(executor.map(process_frame, range(frameCnt)), total=frameCnt, desc=\"Processing frames\"):\n",
    "            for i, patch_table in enumerate(frame_result):\n",
    "                if patch_table is not None:\n",
    "                    if all_patch_tables[i] is None:\n",
    "                        all_patch_tables[i] = patch_table\n",
    "                    else:\n",
    "                        all_patch_tables[i] = pd.concat([all_patch_tables[i], patch_table], ignore_index=True)\n",
    "\n",
    "    # Merge g/r channels and match frames for final output\n",
    "    def merge_patch_table(patch_table, row):\n",
    "        g_df = patch_table[[\"g_frame\", \"g_image\"]].dropna(subset=[\"g_frame\"]).copy()\n",
    "        r_df = patch_table[[\"r_frame\", \"r_image\"]].dropna(subset=[\"r_frame\"]).copy()\n",
    "        g_df[\"frame\"] = g_df[\"g_frame\"].astype(int)\n",
    "        r_df[\"frame\"] = r_df[\"r_frame\"].astype(int)\n",
    "        merged = pd.merge(g_df, r_df, on=\"frame\", how=\"outer\").sort_values(\"frame\").reset_index(drop=True)\n",
    "        for col in [\"g_frame\", \"r_frame\", \"g_image\", \"r_image\"]:\n",
    "            if col in merged.columns:\n",
    "                merged[col] = merged[col].where(pd.notna(merged[col]), None)\n",
    "        merged[\"is_first_g_T\"] = merged[\"frame\"] == row[\"first_g_T\"]\n",
    "        merged[\"is_first_r_T\"] = merged[\"frame\"] == row[\"first_r_T\"]\n",
    "        return merged[[\"frame\", \"g_frame\", \"g_image\", \"r_frame\", \"r_image\", \"is_first_g_T\", \"is_first_r_T\"]]\n",
    "\n",
    "    patch_df[\"patch\"] = [\n",
    "        merge_patch_table(tbl, patch_df.iloc[i]) if tbl is not None else pd.DataFrame(\n",
    "            columns=[\"frame\", \"g_frame\", \"g_image\", \"r_frame\", \"r_image\", \"is_first_g_T\", \"is_first_r_T\"]\n",
    "        )\n",
    "        for i, tbl in enumerate(all_patch_tables)\n",
    "    ]\n",
    "\n",
    "    return patch_df\n",
    "\n",
    "def run_full_analysis(criInter, criIntra, criOverlap, criBlink):\n",
    "    \"\"\"\n",
    "    Run the complete colocalization and dark-region-based analysis pipeline.\n",
    "\n",
    "    This function orchestrates the full image-based track analysis:\n",
    "    1. Loads tracking data and metadata from user-selected TIFF/XML files.\n",
    "    2. Applies filtering to green/red tracks (ROI/FOI, revived, overlapping).\n",
    "    3. Identifies colocalized green-red track pairs.\n",
    "    4. Fits exponential decay to time delay histogram of pairs.\n",
    "    5. Analyzes which pairs occur in dark regions of the RICM channel.\n",
    "    6. Returns starting coordinates and frame index for selected tracks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    criInter : float\n",
    "        Maximum distance to consider two tracks colocalized (inter-track threshold).\n",
    "    criIntra : float\n",
    "        Minimum distance between tracks to be considered distinct (intra-track threshold).\n",
    "    criOverlap : float\n",
    "        Distance threshold below which two tracks are considered overlapping and filtered.\n",
    "    criBlink : float\n",
    "        Duration-based threshold to filter out short-lived tracks (used for blinking filter).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_mark : pd.DataFrame\n",
    "        Table containing ref_id, coordinates, and start frame of marked green/red colocalized tracks\n",
    "        that lie in dark regions of the RICM channel.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Load track data (from XML), image path, metadata, and analysis settings\n",
    "    df_g, df_r, imagefile, pathImgFile, filenamehead, metadata, settings = main_data_loading(\n",
    "        criInter, criIntra, criOverlap, criBlink\n",
    "    )\n",
    "    \n",
    "    # Step 2: Apply filtering on green/red track data (ROI/FOI + revived + overlap removal)\n",
    "    df_g_ol, df_r_ol, df_first_g, df_first_r = run_main_filtering(df_g, df_r, settings)\n",
    "    \n",
    "    # Step 3: Detect primary green-red colocalized pairs based on proximity\n",
    "    primary_pair_df = find_colocalized_pairs_matlab(df_g_ol, df_r_ol, settings[\"criInter\"])\n",
    "\n",
    "    print(\"before loading RICM image\")\n",
    "\n",
    "    # Step 4: Perform time delay histogram analysis and exponential decay fitting (τ, R²)\n",
    "    main_time_delay_fitting(primary_pair_df, metadata, settings)\n",
    "\n",
    "    print(\"after loading RICM image\")\n",
    "\n",
    "    # Step 5: Load full image stack and filter colocalized pairs that overlap with dark regions in RICM\n",
    "    multistack, pairOnDark = main_analysis_after_dark_pairs(imagefile, primary_pair_df, metadata, settings)\n",
    "\n",
    "    # Step 6: For each selected colocalized pair, extract the green/red track's first appearance frame\n",
    "    df_mark = making_mark_start(df_g, df_r, pairOnDark)\n",
    "\n",
    "    return multistack, df_mark\n",
    "\n",
    "def plot_patch_df_grid_grouped(patch_df, pad=10, max_workers=16):\n",
    "    \"\"\"\n",
    "    Visualize side-by-side temporal patches of green and red channel images for each tracked pair.\n",
    "\n",
    "    This function:\n",
    "    - Aligns patches temporally around the first appearance frame of each marker\n",
    "    - Displays a row of green patches and a row of red patches per track\n",
    "    - Uses color-coded bounding boxes to highlight the center (first_T) frame\n",
    "    - Supports parallel rendering for speed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patch_df : pd.DataFrame\n",
    "        DataFrame containing per-track patch data (output from `marker_df_2()`).\n",
    "\n",
    "    pad : int, default=10\n",
    "        Number of frames to include before and after the center frame.\n",
    "\n",
    "    max_workers : int, default=16\n",
    "        Number of threads for parallel rendering.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    figures : list of matplotlib.figure.Figure\n",
    "        A list of rendered matplotlib figures, each visualizing one track’s green/red patch series.\n",
    "    \"\"\"\n",
    "    def center_channel_table(patch_table, channel='g', pad=10):\n",
    "        \"\"\"\n",
    "        Extract and center the image patch table around the marker's first appearance frame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        patch_table : pd.DataFrame\n",
    "            Table of frames and images for a given marker.\n",
    "        channel : str\n",
    "            Either 'g' or 'r' for green/red channel.\n",
    "        pad : int\n",
    "            How many frames before and after the center to show.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df_merged : pd.DataFrame\n",
    "            Table with fixed offsets around center frame, padded with NaNs if needed.\n",
    "        \"\"\"\n",
    "        frame_col = f\"{channel}_frame\"\n",
    "        image_col = f\"{channel}_image\"\n",
    "        highlight_col = f\"is_first_{channel}_T\"\n",
    "\n",
    "        df = patch_table[[frame_col, image_col, highlight_col]].copy()\n",
    "        df.columns = [\"frame\", \"image\", \"highlight\"]\n",
    "        df = df[pd.notna(df[\"frame\"])].sort_values(\"frame\").reset_index(drop=True)\n",
    "\n",
    "        # Identify the frame where the marker first appears\n",
    "        center_rows = df[df[\"highlight\"]]\n",
    "        if center_rows.empty:\n",
    "            return None\n",
    "        center_frame = center_rows[\"frame\"].iloc[0]\n",
    "\n",
    "        # Add relative offset from center frame\n",
    "        df[\"offset\"] = df[\"frame\"] - center_frame\n",
    "        df = df[df[\"offset\"].between(-pad, pad)]\n",
    "\n",
    "        # Create full offset range and merge to maintain fixed frame layout\n",
    "        full_offsets = np.arange(-pad, pad + 1)\n",
    "        df_full = pd.DataFrame({\"offset\": full_offsets})\n",
    "        df_merged = df_full.merge(df, on=\"offset\", how=\"left\")\n",
    "        return df_merged\n",
    "\n",
    "    def render_single_row(row, pad, n_cols):\n",
    "        \"\"\"\n",
    "        Render a single row (i.e., one marker) as a 2-row image grid with green/red patch timelines.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        row : pd.Series\n",
    "            A row from the patch_df.\n",
    "        pad : int\n",
    "            Padding around center frame.\n",
    "        n_cols : int\n",
    "            Total number of columns to display (2*pad + 1).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fig : matplotlib.figure.Figure\n",
    "            A rendered figure for one marker.\n",
    "        \"\"\"\n",
    "        patch_table = row[\"patch\"]\n",
    "        ref_id = row[\"ref_id\"]\n",
    "\n",
    "        g_table = center_channel_table(patch_table, 'g', pad=pad)\n",
    "        r_table = center_channel_table(patch_table, 'r', pad=pad)\n",
    "\n",
    "        fig, axes = plt.subplots(2, n_cols, figsize=(20, 3))\n",
    "        axes = axes.reshape(2, n_cols)\n",
    "\n",
    "        # Plot each frame's image for both channels\n",
    "        for i in range(n_cols):\n",
    "            for j, (table, color, ch) in enumerate([(g_table, 'green', 'g'), (r_table, 'red', 'r')]):\n",
    "                ax = axes[j, i]\n",
    "                if table is not None and isinstance(table.at[i, \"image\"], np.ndarray):\n",
    "                    img = table.at[i, \"image\"]\n",
    "                    ax.imshow(img)\n",
    "\n",
    "                    frame_val = table.at[i, \"frame\"]\n",
    "                    if pd.notna(frame_val):\n",
    "                        ax.set_title(f\"{ch}{int(frame_val)}\", fontsize=6)\n",
    "\n",
    "                    # Highlight the first appearance frame\n",
    "                    if table.at[i, \"highlight\"]:\n",
    "                        ax.add_patch(patches.Rectangle((0, 0), img.shape[1], img.shape[0],\n",
    "                                                       linewidth=2, edgecolor=color, facecolor='none'))\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "        # Add reference ID label at the top center\n",
    "        mid_ax = axes[0, n_cols // 2]\n",
    "        mid_ax.text(0.5, 1.1, f\"ref_id: {ref_id}\", ha='center', va='bottom',\n",
    "                    transform=mid_ax.transAxes, fontsize=8, color='black')\n",
    "\n",
    "        fig.subplots_adjust(left=0.01, right=0.99, top=0.85, bottom=0.05, wspace=0.05, hspace=0.05)\n",
    "        return fig\n",
    "\n",
    "    # Sort DataFrame by ID group for consistent visual grouping\n",
    "    patch_df = patch_df.copy()\n",
    "    patch_df['id_group'] = pd.Categorical(patch_df['id_group'], categories=[\"common\", \"only1\", \"only2\"], ordered=True)\n",
    "    patch_df = patch_df.sort_values(\"id_group\").reset_index(drop=True)\n",
    "\n",
    "    n_cols = pad * 2 + 1  # Number of columns in grid (before/after center frame)\n",
    "\n",
    "    figures = []\n",
    "\n",
    "    # Parallel processing for each marker row\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(render_single_row, row, pad, n_cols) for _, row in patch_df.iterrows()]\n",
    "        for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Rendering\"):\n",
    "            try:\n",
    "                fig = f.result()\n",
    "                if fig:\n",
    "                    figures.append(fig)\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Failed to render figure: {e}\")\n",
    "\n",
    "    return figures\n",
    "\n",
    "def combine_figures_to_one_subplot(figures, dpi=100):\n",
    "    \"\"\"\n",
    "    Combine a list of matplotlib figures into a single vertically stacked image.\n",
    "\n",
    "    This function:\n",
    "    - Converts each individual matplotlib figure into an RGB image\n",
    "    - Stacks all images vertically into a single canvas\n",
    "    - Displays the result as one subplot\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    figures : list of matplotlib.figure.Figure\n",
    "        List of matplotlib figures to be combined.\n",
    "\n",
    "    dpi : int, default=100\n",
    "        Resolution for displaying the final combined figure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function directly displays the final combined image using matplotlib.\n",
    "    \"\"\"\n",
    "    rendered_imgs = []\n",
    "\n",
    "    for fig in figures:\n",
    "        # Convert the matplotlib figure to a NumPy array using backend canvas\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "\n",
    "        # Retrieve RGBA buffer and convert to RGB (drop alpha)\n",
    "        width, height = fig.canvas.get_width_height()\n",
    "        img = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8).reshape((height, width, 4))[:, :, :3]\n",
    "        rendered_imgs.append(img)\n",
    "\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "    # Calculate total height and maximum width for the final canvas\n",
    "    total_height = sum(img.shape[0] for img in rendered_imgs)\n",
    "    max_width = max(img.shape[1] for img in rendered_imgs)\n",
    "\n",
    "    # Create a blank white canvas\n",
    "    final_canvas = np.ones((total_height, max_width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Copy each image into the final canvas (top-down)\n",
    "    y = 0\n",
    "    for img in rendered_imgs:\n",
    "        h, w = img.shape[:2]\n",
    "        final_canvas[y:y + h, :w] = img\n",
    "        y += h\n",
    "\n",
    "    # Display the final combined image\n",
    "    plt.figure(figsize=(max_width / dpi, total_height / dpi))\n",
    "    plt.imshow(final_canvas)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is an example of the execution pipeline for the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for criOverlap = 1.0\n",
    "multistack_10, df_mark_10 = run_full_analysis(0.6, 0.6, 1.0, 2.0)\n",
    "\n",
    "# Run for criOverlap = 2.5\n",
    "multistack_25, df_mark_25 = run_full_analysis(0.6, 0.6, 2.5, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_df = marker_df_2(\n",
    "    multistack_10,\n",
    "    df_mark_10, df_mark_25,\n",
    "    alpha=1.0,\n",
    "    green_gain=1.0,\n",
    "    red_gain=1.0,\n",
    "    green_contrast=1.0,\n",
    "    red_contrast=1.0,\n",
    "    green_gamma=1.0,\n",
    "    red_gamma=1.0,\n",
    "    use_gamma=False,\n",
    "    marker_radius=5,\n",
    "    radius_px=13,\n",
    "    max_workers=16,\n",
    "    use_combined=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_df = patch_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_table = patch_df.loc[patch_df[\"first_g_T\"] - patch_df[\"first_r_T\"] > 0].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = plot_patch_df_grid_grouped(patch_table, pad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_figures_to_one_subplot(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are functions reserved for future improvements and not currently in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_revived_filter(df_first: pd.DataFrame, cri_intra: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    반경 cri_intra 이내에 있는 점들 중에서 가장 먼저 등장한 것만 남긴다.\n",
    "    KDTree 기반 greedy 방식으로 1개씩 선택하며 중복 제거.\n",
    "    \"\"\"\n",
    "    coords = df_first[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    times = df_first[\"T_first\"].to_numpy()\n",
    "\n",
    "    # 빠른 등장 순으로 정렬 (동시간이면 index 기준으로 안정정렬)\n",
    "    order = np.lexsort((np.arange(len(times)), times))\n",
    "    used = np.full(len(df_first), False)\n",
    "    keep_indices = []\n",
    "\n",
    "    tree = cKDTree(coords)\n",
    "\n",
    "    for i in order:\n",
    "        if used[i]:\n",
    "            continue\n",
    "        keep_indices.append(i)\n",
    "        neighbors = tree.query_ball_point(coords[i], r=cri_intra)\n",
    "        used[neighbors] = True  # 자신과 반경 이웃 모두 제거\n",
    "\n",
    "    return df_first.iloc[keep_indices].reset_index(drop=True)\n",
    "\n",
    "def apply_revived_filter_v2(df: pd.DataFrame, cri_intra: float, blinking_duration: float) -> pd.DataFrame:\n",
    "    coords = df[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    times_first = df[\"T_first\"].to_numpy()\n",
    "    times_last = df[\"T_last\"].to_numpy()\n",
    "    keep = np.full(len(df), True)\n",
    "\n",
    "    order = np.lexsort((np.arange(len(times_first)), times_first))  # 시간 오름차순\n",
    "    tree = cKDTree(coords)\n",
    "\n",
    "    for i in order:\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        neighbors = tree.query_ball_point(coords[i], r=cri_intra)\n",
    "        for j in neighbors:\n",
    "            if j == i or not keep[j]:\n",
    "                continue\n",
    "\n",
    "            # 양방향 blinking 판별\n",
    "            blink_ij = times_first[i] - times_last[j]\n",
    "            blink_ji = times_first[j] - times_last[i]\n",
    "\n",
    "            if 0 < blink_ij <= blinking_duration:\n",
    "                keep[j] = False\n",
    "            elif 0 < blink_ji <= blinking_duration:\n",
    "                keep[i] = False\n",
    "\n",
    "    return df[keep].reset_index(drop=True)\n",
    "\n",
    "def apply_overlapping_filter(df: pd.DataFrame, cri_overlap: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    KDTree 기반 greedy 방식으로 반경 내 overlapping spot 중 하나만 남긴다.\n",
    "    중복 없이 선택하며, T_first가 있으면 우선순위로 사용한다.\n",
    "    \"\"\"\n",
    "    coords = df[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    times = df[\"T_first\"].to_numpy() if \"T_first\" in df.columns else np.zeros(len(df))\n",
    "    \n",
    "    # 우선순위 기준 정렬: T_first가 빠른 순\n",
    "    order = np.lexsort((np.arange(len(times)), times))  # stable sort\n",
    "    used = np.full(len(df), False)\n",
    "    keep_indices = []\n",
    "\n",
    "    tree = cKDTree(coords)\n",
    "\n",
    "    for i in order:\n",
    "        if used[i]:\n",
    "            continue\n",
    "        keep_indices.append(i)\n",
    "        neighbors = tree.query_ball_point(coords[i], r=cri_overlap)\n",
    "        used[neighbors] = True  # 이웃 모두 제거 (자기 자신 포함)\n",
    "\n",
    "    return df.iloc[keep_indices].reset_index(drop=True)\n",
    "\n",
    "def apply_overlapping_filter_v2(df: pd.DataFrame, cri_overlap: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    KDTree 기반 greedy 방식으로 반경 내 overlapping spot 중 하나만 남긴다.\n",
    "    중복 없이 선택하며, T_first가 있으면 우선순위로 사용한다.\n",
    "    \"\"\"\n",
    "    coords = df[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    times_first = df[\"T_first\"].to_numpy() if \"T_first\" in df.columns else np.zeros(len(df))\n",
    "    times_last = df[\"T_last\"].to_numpy() if \"T_last\" in df.columns else np.zeros(len(df))\n",
    "    \n",
    "    # 우선순위 기준 정렬: T_first가 빠른 순\n",
    "    order = np.lexsort((np.arange(len(times_first)), times_first))  # stable sort\n",
    "    used = np.full(len(df), False)\n",
    "    keep_indices = []\n",
    "\n",
    "    tree = cKDTree(coords)\n",
    "\n",
    "    for i in order:\n",
    "        if used[i]:\n",
    "            continue\n",
    "        keep_indices.append(i)\n",
    "\n",
    "        neighbors = tree.query_ball_point(coords[i], r=cri_overlap)\n",
    "        for j in neighbors:\n",
    "            if i == j:\n",
    "                continue\n",
    "            if not (times_last[j] < times_first[i] or times_first[j] > times_last[i]):\n",
    "                used[j] = True\n",
    "        used[i] = True\n",
    "\n",
    "    return df.iloc[keep_indices].reset_index(drop=True)\n",
    "\n",
    "def find_colocalized_pairs(df1, df2, criInter):\n",
    "    coords1 = df1[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    coords2 = df2[[\"X_center\", \"Y_center\"]].to_numpy()\n",
    "    times1 = df1[\"T_first\"].to_numpy()\n",
    "    times2 = df2[\"T_first\"].to_numpy()\n",
    "\n",
    "    tree2 = cKDTree(coords2)\n",
    "\n",
    "    pair_candidates = []\n",
    "\n",
    "    for i, (coord1, t1) in enumerate(zip(coords1, times1)):\n",
    "        dists, idxs = tree2.query(coord1, k=len(coords2), distance_upper_bound=criInter)\n",
    "\n",
    "        # dists, idxs 는 거리순 정렬되어 있음\n",
    "        for dist, j in zip(dists, idxs):\n",
    "            if j == len(coords2) or not np.isfinite(dist):\n",
    "                break  # bound 초과 or invalid\n",
    "            pair_candidates.append((i, j, dist))\n",
    "\n",
    "            break  # 가장 가까운 하나만 남기고 종료\n",
    "\n",
    "    # 이제 df2 중복 제거: greedy 방식\n",
    "    used_df2 = set()\n",
    "    pairs = []\n",
    "\n",
    "    for i, j, dist in sorted(pair_candidates, key=lambda x: x[2]):\n",
    "        if j in used_df2:\n",
    "            continue\n",
    "        used_df2.add(j)\n",
    "\n",
    "        t1 = times1[i]\n",
    "        t2 = times2[j]\n",
    "        coord1 = coords1[i]\n",
    "        coord2 = coords2[j]\n",
    "        timedelay = int(round(t1)) - int(round(t2))\n",
    "\n",
    "        pairs.append([\n",
    "            timedelay,\n",
    "            dist,\n",
    "            df1.iloc[i][\"track_id\"], t1, coord1[0], coord1[1],\n",
    "            df2.iloc[j][\"track_id\"], t2, coord2[0], coord2[1]\n",
    "        ])\n",
    "\n",
    "    return pd.DataFrame(pairs, columns=[\n",
    "        \"time_delay\", \"distance\",\n",
    "        \"ref_id\", \"ref_T\", \"ref_X\", \"ref_Y\",\n",
    "        \"cmp_id\", \"cmp_T\", \"cmp_X\", \"cmp_Y\"\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
