{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from scipy.io import loadmat\n",
    "from skimage.transform import warp\n",
    "from tifffile import imwrite\n",
    "from pathlib import Path\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "from numpy.fft import fftn, ifftn\n",
    "from scipy.ndimage import fourier_shift\n",
    "from skimage.transform import AffineTransform, warp\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afaba41",
   "metadata": {},
   "source": [
    "## ImageJ + TrackMate Integration Setup (via pyimagej & scyjava)\n",
    "\n",
    "This section initializes the **ImageJ** environment with full access to **TrackMate** and other legacy plugins through `pyimagej` and `scyjava`.\n",
    "\n",
    "### Key Features:\n",
    "- Allocates up to **16 GB of Java heap memory** for large image processing tasks.\n",
    "- Launches **Fiji (ImageJ distribution)** in **headless mode**, allowing non-GUI execution.\n",
    "- Loads all necessary **Java classes** to control ImageJ and TrackMate via Python.\n",
    "- Provides aliases for essential TrackMate modules: detection, tracking, filtering, and export.\n",
    "\n",
    "### Java Classes Imported:\n",
    "| Category              | Classes / Purpose                                                       |\n",
    "|-----------------------|-------------------------------------------------------------------------|\n",
    "| **Core ImageJ**       | `ChannelSplitter`, `BackgroundSubtracter`, `WindowManager`, `ImagePlus` |\n",
    "| **Java Utilities**    | `Integer`, `HashMap`, `File`                                            |\n",
    "| **TrackMate Core**    | `Model`, `Settings`, `TrackMate`, `Logger`                              |\n",
    "| **TrackMate Tools**   | `LogDetectorFactory`, `SparseLAPTrackerFactory`, `FeatureFilter`, `ExportTracksToXML` |\n",
    "\n",
    "### Output\n",
    "Once executed, the script will print the current ImageJ version to confirm successful initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7563529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej, scyjava\n",
    "\n",
    "# Set the maximum heap memory for the JVM to 16 GB\n",
    "scyjava.config.add_options(\"-Xmx16g\")\n",
    "\n",
    "# Initialize ImageJ with legacy mode enabled.\n",
    "# It is important to use add_legacy=True to enable TrackMate and other legacy plugins.\n",
    "# Note: 'headless=True' is replaced by 'mode=\"headless\"' in modern ImageJ.\n",
    "ij = imagej.init(\"sc.fiji:fiji\", mode=\"headless\", add_legacy=True)\n",
    "\n",
    "# Import key ImageJ Java classes using scyjava.jimport\n",
    "ChannelSplitter  = scyjava.jimport('ij.plugin.ChannelSplitter')                  # Used to split multichannel images\n",
    "BackgroundSub    = scyjava.jimport('ij.plugin.filter.BackgroundSubtracter')      # Used for background subtraction\n",
    "WindowManager    = scyjava.jimport('ij.WindowManager')                           # Manages open image windows in ImageJ\n",
    "ImagePlus        = scyjava.jimport('ij.ImagePlus')                               # Core image container class\n",
    "JavaArray        = scyjava.jarray(ImagePlus, 0)                                  # Placeholder for ImagePlus Java array\n",
    "\n",
    "# Print the current version of ImageJ for verification\n",
    "print(\"ImageJ:\", ij.getVersion())\n",
    "\n",
    "# Aliases for frequently used Java classes\n",
    "Integer = scyjava.jimport(\"java.lang.Integer\")       # Java Integer class\n",
    "HashMap = scyjava.jimport(\"java.util.HashMap\")       # Java HashMap for parameter passing\n",
    "File    = scyjava.jimport(\"java.io.File\")            # Java File class for file I/O\n",
    "\n",
    "# Import core TrackMate classes for tracking\n",
    "Model     = scyjava.jimport(\"fiji.plugin.trackmate.Model\")                       # Represents the tracking model\n",
    "Settings  = scyjava.jimport(\"fiji.plugin.trackmate.Settings\")                    # Stores all settings for tracking\n",
    "TrackMate = scyjava.jimport(\"fiji.plugin.trackmate.TrackMate\")                   # Main execution class for TrackMate\n",
    "\n",
    "# Import TrackMate utilities for detection, tracking, filtering, and export\n",
    "FeatureFilter            = scyjava.jimport(\"fiji.plugin.trackmate.features.FeatureFilter\")                # Used to filter features like quality, duration, displacement\n",
    "LogDetectorFactory       = scyjava.jimport(\"fiji.plugin.trackmate.detection.LogDetectorFactory\")          # LoG-based spot detector\n",
    "SparseLAPTrackerFactory  = scyjava.jimport(\"fiji.plugin.trackmate.tracking.jaqaman.SparseLAPTrackerFactory\")  # Core tracker factory using LAP framework\n",
    "ExportTracksToXML        = scyjava.jimport(\"fiji.plugin.trackmate.action.ExportTracksToXML\")              # Export tracking results to XML\n",
    "Logger                   = scyjava.jimport(\"fiji.plugin.trackmate.Logger\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c9c7c",
   "metadata": {},
   "source": [
    "## Configuration & Input Paths for TrackMate-based Image Analysis\n",
    "\n",
    "This section defines all necessary input paths and parameter sets for running the full TrackMate-based pipeline, including drift correction and chromatic registration.\n",
    "\n",
    "---\n",
    "\n",
    "### Input Paths\n",
    "\n",
    "| Variable       | Description                                |\n",
    "|----------------|--------------------------------------------|\n",
    "| `nd2_path`     | Path to the input `.nd2` file (raw microscopy stack) |\n",
    "| `mat_path`     | Path to the `.mat` file containing 3×3 affine matrix (`T`) for chromatic registration |\n",
    "| `imagej_path`  | Path to the ImageJ executable (if needed for launching manually or troubleshooting) |\n",
    "\n",
    "---\n",
    "\n",
    "### General Drift Correction Configuration (`config`)\n",
    "\n",
    "This configuration is used for the initial tracking and drift correction phase using a specific channel.\n",
    "\n",
    "| Key                     | Description |\n",
    "|-------------------------|-------------|\n",
    "| `n_channels`            | Total number of channels in the image stack (e.g., 3) |\n",
    "| `target_chan`           | Channel used for drift tracking (e.g., 3 = red) |\n",
    "| `spot_radius`           | Approximate radius of features/spots |\n",
    "| `threshold`             | Minimum intensity for spot detection |\n",
    "| `subpixel`              | Enable subpixel refinement for detection |\n",
    "| `median_filter`         | Apply median filtering before detection |\n",
    "| `linking_max`           | Max distance for linking spots |\n",
    "| `gapclosing_max`        | Max distance for closing temporal gaps |\n",
    "| `max_frame_gap`         | Max number of allowed gap frames |\n",
    "| `allow_split/merge`     | Whether to allow track splitting or merging |\n",
    "| `filter_quality`        | Apply spot filtering by quality score |\n",
    "| `quality_cutoff`        | Minimum quality value |\n",
    "| `filter_displacement`   | Apply track filtering by displacement |\n",
    "| `displacement_cutoff`   | Minimum allowed displacement |\n",
    "| `filter_duration`       | Apply track filtering by duration |\n",
    "| `duration_cutoff_time`  | Minimum track duration in seconds (NaN = auto-compute) |\n",
    "| `target_registration_chan` | Channel to apply chromatic registration |\n",
    "\n",
    "---\n",
    "\n",
    "### Green Channel Tracking Configuration (`config_green`)\n",
    "\n",
    "Used for running TrackMate on channel 2 (green) during dual-channel tracking.\n",
    "\n",
    "- High intensity threshold due to brighter signal\n",
    "- No displacement filter\n",
    "- Includes filtering based on duration and early track start\n",
    "\n",
    "---\n",
    "\n",
    "### Red Channel Tracking Configuration (`config_red`)\n",
    "\n",
    "Used for running TrackMate on channel 3 (red) during dual-channel tracking.\n",
    "\n",
    "- Lower threshold due to dimmer red signal\n",
    "- Similar structure to `config_green` with independent settings\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "These configurations feed into:\n",
    "- `run_precorrection()` for full pipeline execution (drift + chromatic correction + merge)\n",
    "- `run_trackmate_dual_channel_from_config()` for channel-specific dual tracking\n",
    "- XML export for downstream time delay or colocalization analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b010f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "nd2_path = \"D:/Jo_Lab/230501_THP1_LDVPdp2036_2.5s_paBleb/cham1_paBleb10uM/new/1.ND2_file/paBleb10uM_cham1_002.nd2\"\n",
    "mat_path = \"D:/Jo_Lab/chromaticErr/tform_matrix_only_2.mat\"\n",
    "imagej_path = \"C:/Users/KU/Desktop/fiji-win64/Fiji.app/ImageJ-win64.exe\"\n",
    "\n",
    "# Configurations\n",
    "config = {\n",
    "    \"n_channels\": 3,  # Total number of image channels (e.g., 3 for RGB, or 3 grayscale slices)\n",
    "\n",
    "    \"target_chan\": 3,  # Channel index used for drift tracking (1-based, as expected by ImageJ/TrackMate)\n",
    "\n",
    "    # Spot detection parameters\n",
    "    \"spot_radius\": 2.5,       # Approximate spot radius (in pixels) for detection\n",
    "    \"threshold\": 20.0,        # Intensity threshold for spot detection\n",
    "    \"subpixel\": True,         # Enable subpixel localization refinement\n",
    "    \"median_filter\": False,   # Apply median filtering before detection (reduces noise)\n",
    "\n",
    "    # Linking & tracking parameters\n",
    "    \"linking_max\": 1.0,       # Maximum linking distance between consecutive frames (in pixels)\n",
    "    \"gapclosing_max\": 1.0,    # Maximum distance for closing gaps between tracks\n",
    "    \"max_frame_gap\": 0,       # Maximum number of frames to allow gap closing\n",
    "\n",
    "    # Track structure behaviors\n",
    "    \"allow_split\": False,     # Allow splitting of tracks (e.g., cell division)\n",
    "    \"allow_merge\": False,     # Allow merging of tracks (e.g., convergence)\n",
    "\n",
    "    # Track filtering\n",
    "    \"filter_quality\": True,        # Filter spots by quality score\n",
    "    \"quality_cutoff\": 0.0,         # Minimum quality threshold\n",
    "    \"filter_displacement\": True,   # Filter tracks by total displacement\n",
    "    \"displacement_cutoff\": 0.0,    # Minimum displacement for track to be retained\n",
    "    \"filter_duration\": True,       # Filter tracks by duration\n",
    "    \"duration_cutoff_time\": math.nan,  # Minimum duration (in seconds); if NaN, auto-calculated from frames\n",
    "\n",
    "    # Chromatic registration\n",
    "    \"target_registration_chan\": 3  # Channel index to which chromatic registration is applied\n",
    "}\n",
    "\n",
    "config_green = {\n",
    "    \"target_chan\": 2,              # Channel index to analyze (Green channel)\n",
    "\n",
    "    # Spot detection settings\n",
    "    \"spot_radius\": 2.5,            # Estimated radius of the spots to detect\n",
    "    \"threshold\": 100.0,            # Intensity threshold for spot detection\n",
    "    \"subpixel\": True,              # Enable subpixel localization\n",
    "    \"median_filter\": False,        # Apply median filter before detection (noise reduction)\n",
    "\n",
    "    # Tracking and linking settings\n",
    "    \"linking_max\": 1.0,            # Max distance allowed for linking spots (in pixels)\n",
    "    \"gapclosing_max\": 0.6,         # Max distance for gap closing\n",
    "    \"max_frame_gap\": 5,            # Max number of frames allowed for gap closing\n",
    "\n",
    "    # Track behavior\n",
    "    \"allow_split\": False,          # Disallow track splitting\n",
    "    \"allow_merge\": False,          # Disallow track merging\n",
    "\n",
    "    # Track filtering options\n",
    "    \"displacement_cutoff\": 1.5,    # Minimum displacement (ignored if filter_displacement=False)\n",
    "    \"filter_displacement\": False,  # Disable displacement-based track filtering\n",
    "\n",
    "    \"duration_cutoff_time\": 2.5,   # Minimum track duration in time units (e.g., seconds)\n",
    "    \"filter_duration\": True,       # Enable duration-based track filtering\n",
    "\n",
    "    \"filter_quality\": True,        # Enable filtering based on spot quality\n",
    "    \"quality_cutoff\": 0.0,         # Minimum spot quality threshold\n",
    "\n",
    "    \"filter_track_start\": True,    # Filter out tracks that start too early\n",
    "    \"track_start_time\": 1          # Minimum start time (frame index) for a track to be retained\n",
    "}\n",
    "\n",
    "config_red = {\n",
    "    \"target_chan\": 3,              # Channel index to analyze (Red channel)\n",
    "\n",
    "    # Spot detection settings\n",
    "    \"spot_radius\": 2.5,\n",
    "    \"threshold\": 40.0,             # Lower threshold due to dimmer red signal\n",
    "    \"subpixel\": True,\n",
    "    \"median_filter\": False,\n",
    "\n",
    "    # Tracking and linking settings\n",
    "    \"linking_max\": 1.0,\n",
    "    \"gapclosing_max\": 0.6,\n",
    "    \"max_frame_gap\": 5,\n",
    "\n",
    "    # Track behavior\n",
    "    \"allow_split\": False,\n",
    "    \"allow_merge\": False,\n",
    "\n",
    "    # Track filtering options\n",
    "    \"displacement_cutoff\": 1.5,\n",
    "    \"filter_displacement\": False,\n",
    "\n",
    "    \"duration_cutoff_time\": 2.5,\n",
    "    \"filter_duration\": True,\n",
    "\n",
    "    \"filter_quality\": True,\n",
    "    \"quality_cutoff\": 0.0,\n",
    "\n",
    "    \"filter_track_start\": True,\n",
    "    \"track_start_time\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05735b",
   "metadata": {},
   "source": [
    "# MasterMacro Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Function Call Hierarchy\n",
    "\n",
    "```text\n",
    "run_precorrection\n",
    "├── run_trackmate_nd2\n",
    "│   └── TrackMate tracking & export (XML, TIFF, metadata)\n",
    "├── load_tracks_xml\n",
    "├── compute_median_drift_from_tracks\n",
    "├── save_drift_trace_txt\n",
    "├── apply_drift_correction_to_tiff\n",
    "│   └── Fourier shift applied per-channel\n",
    "├── apply_chromatic_registration_from_mat\n",
    "│   └── AffineTransform (scikit-image warp)\n",
    "└── combine_tif_channels\n",
    "    └── ImageJ merge via pyimagej\n",
    "\n",
    "run_trackmate_dual_channel_from_config\n",
    "├── run_single_channel (green)\n",
    "└── run_single_channel (red)\n",
    "    └── TrackMate on multichannel TIFF\n",
    "\n",
    "subtract_background_and_merge\n",
    "├── ImageJ channel split\n",
    "├── Background subtraction (C2, C3)\n",
    "└── Channel merge (C1 + corrected C2/C3)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Variables & Paths\n",
    "\n",
    "| Variable | Description |\n",
    "|---------|-------------|\n",
    "| `nd2_path` | Input raw image file in ND2 format |\n",
    "| `track_dir` | Directory for TrackMate XML and TIF output |\n",
    "| `reg_dir` | Directory for drift-corrected results |\n",
    "| `mat_path` | MATLAB `.mat` file with 3x3 affine transform |\n",
    "| `drift_trace` | NumPy array of XY drift per frame |\n",
    "| `description_template` | Metadata string for TIFF description field |\n",
    "\n",
    "---\n",
    "\n",
    "## Full Execution Flow\n",
    "\n",
    "### `run_precorrection()`\n",
    "1. Create output folders (2, 3)\n",
    "2. Run TrackMate on ND2 → XML + TIF export\n",
    "3. Load tracks and compute median XY drift\n",
    "4. Apply drift correction to all channels\n",
    "5. Apply chromatic correction to registration channel\n",
    "6. Merge all corrected channels into multichannel TIF\n",
    "\n",
    "### `run_trackmate_dual_channel_from_config()`\n",
    "1. Open multichannel TIFF\n",
    "2. Run TrackMate separately for green and red channels\n",
    "3. Apply spot filtering and duration filters\n",
    "4. Export tracking results as XML (g and r)\n",
    "\n",
    "### `subtract_background_and_merge()`\n",
    "1. Load multichannel TIFF and split into C1, C2, C3\n",
    "2. Apply background subtraction on C2 and C3\n",
    "3. Merge C1 + corrected C2 + corrected C3 (in slot 4)\n",
    "4. Save merged image as new TIFF\n",
    "\n",
    "---\n",
    "\n",
    "## Sample Output File Names\n",
    "```text\n",
    "ND2 input:             sample.nd2\n",
    "TrackMate XML:         sample_Tracks.xml\n",
    "Raw TIFF:              sample.tif\n",
    "Drift trace:           sample_drift.txt\n",
    "Corrected TIFFs:       sample_chan1_drftc.tif, sample_chan2_drftc.tif, ...\n",
    "Registered TIF:        sample_drftc_reg.tif\n",
    "Dual XML (g, r):       sample_drftc_reg_g.xml, sample_drftc_reg_r.xml\n",
    "Backsub TIFF:          sample_back.tif\n",
    "```\n",
    "---\n",
    "\n",
    "## Example Image Shapes\n",
    "\n",
    "| File Type          | Shape         | Description             |\n",
    "|--------------------|---------------|-------------------------|\n",
    "| Raw ND2            | (T, Y, X, C)  | 4D hyperstack           |\n",
    "| Track TIFF         | (T, Y, X, C)  | Uncorrected export      |\n",
    "| Corrected TIFF     | (T, Y, X)     | Per-channel TIFF        |\n",
    "| Merged TIF         | (T, Y, X, C)  | Final drift-corrected   |\n",
    "| Background-sub TIFF| (T, Y, X, C)  | After subtract_background|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351afd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trackmate_nd2(\n",
    "    nd2_paths,\n",
    "    out_dir,\n",
    "    target_chan=3,\n",
    "    spot_radius=2.5,\n",
    "    threshold=20.0,\n",
    "    subpixel=True,\n",
    "    median_filter=False,\n",
    "    linking_max=1.0,\n",
    "    gapclosing_max=1.0,\n",
    "    max_frame_gap=0,\n",
    "    allow_split=False,\n",
    "    allow_merge=False,\n",
    "    filter_quality=True,\n",
    "    quality_cutoff=0.0,\n",
    "    filter_displacement=True,\n",
    "    displacement_cutoff=0.0,\n",
    "    filter_duration=True,\n",
    "    duration_cutoff_time=math.nan,\n",
    "):\n",
    "    '''\n",
    "    Run TrackMate on ND2 files for spot detection and tracking,\n",
    "    and export results including XML tracks, TIF images, and metadata.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nd2_paths : str or Path or list\n",
    "        Path(s) to ND2 image file(s) to be processed.\n",
    "    out_dir : str or Path\n",
    "        Output directory where results (XML, TIF, metadata) will be saved.\n",
    "    target_chan : int, default=3\n",
    "        Channel index (1-based) for spot detection.\n",
    "    spot_radius : float, default=2.5\n",
    "        Radius of spots to be detected.\n",
    "    threshold : float, default=20.0\n",
    "        Intensity threshold for spot detection.\n",
    "    subpixel : bool, default=True\n",
    "        Whether to enable subpixel localization.\n",
    "    median_filter : bool, default=False\n",
    "        Whether to apply median filter before detection.\n",
    "    linking_max : float, default=1.0\n",
    "        Maximum linking distance for track continuation.\n",
    "    gapclosing_max : float, default=1.0\n",
    "        Maximum distance allowed for closing temporal gaps.\n",
    "    max_frame_gap : int, default=0\n",
    "        Maximum number of frames allowed for gap closing.\n",
    "    allow_split : bool, default=False\n",
    "        Whether to allow track splitting.\n",
    "    allow_merge : bool, default=False\n",
    "        Whether to allow track merging.\n",
    "    filter_quality : bool, default=True\n",
    "        Apply filtering based on spot quality.\n",
    "    quality_cutoff : float, default=0.0\n",
    "        Minimum quality value for spots to be retained.\n",
    "    filter_displacement : bool, default=True\n",
    "        Filter tracks based on displacement.\n",
    "    displacement_cutoff : float, default=0.0\n",
    "        Minimum displacement required to keep the track.\n",
    "    filter_duration : bool, default=True\n",
    "        Filter tracks based on duration.\n",
    "    duration_cutoff_time : float, default=nan\n",
    "        Minimum duration (in time units) required to keep the track.\n",
    "        If NaN, it is automatically calculated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_xmls : list of Path\n",
    "        List of paths to the exported TrackMate XML result files.\n",
    "    '''\n",
    "\n",
    "    if isinstance(nd2_paths, (str, Path)):\n",
    "        nd2_paths = [nd2_paths]\n",
    "\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out_xmls = []\n",
    "\n",
    "    for nd2 in map(Path, nd2_paths):\n",
    "        print(f\"> Processing {nd2.name}\")\n",
    "\n",
    "        # Load ND2 image using Bio-Formats\n",
    "        imp = ij.IJ.openImage(str(nd2))\n",
    "        if imp is None:\n",
    "            print(\"  Warning: Failed to load with Bio-Formats:\", nd2)\n",
    "            continue\n",
    "        imp.show()\n",
    "\n",
    "        # Reset spatial scale to unitless (match MATLAB convention)\n",
    "        cal = imp.getCalibration()\n",
    "        cal.setUnit(\"\")\n",
    "        cal.pixelWidth = cal.pixelHeight = cal.pixelDepth = 1.0\n",
    "        imp.setCalibration(cal)\n",
    "\n",
    "        # Compute duration cutoff (if not provided)\n",
    "        frame_interval = cal.frameInterval\n",
    "        nT = imp.getDimensions()[4]\n",
    "        if math.isnan(duration_cutoff_time):\n",
    "            duration_cutoff = frame_interval * (nT - 1.5)\n",
    "        else:\n",
    "            duration_cutoff = duration_cutoff_time\n",
    "\n",
    "        # Initialize TrackMate model and logger\n",
    "        model = Model()\n",
    "        model.setLogger(Logger.IJ_LOGGER)\n",
    "        model.setPhysicalUnits(cal.getUnit(), cal.getTimeUnit())\n",
    "\n",
    "        # Create settings from the image\n",
    "        settings = Settings(imp)\n",
    "\n",
    "        # Configure detector settings\n",
    "        settings.detectorFactory = LogDetectorFactory()\n",
    "        det = HashMap()\n",
    "        det.put(\"DO_SUBPIXEL_LOCALIZATION\", subpixel)\n",
    "        det.put(\"RADIUS\", spot_radius)\n",
    "        det.put(\"TARGET_CHANNEL\", Integer.valueOf(target_chan))\n",
    "        det.put(\"THRESHOLD\", threshold)\n",
    "        det.put(\"DO_MEDIAN_FILTERING\", median_filter)\n",
    "        settings.detectorSettings = det\n",
    "\n",
    "        # Apply spot quality filter\n",
    "        if filter_quality:\n",
    "            settings.addSpotFilter(FeatureFilter(\"QUALITY\", quality_cutoff, True))\n",
    "\n",
    "        # Configure tracker settings\n",
    "        settings.trackerFactory = SparseLAPTrackerFactory()\n",
    "        trk = settings.trackerFactory.getDefaultSettings()\n",
    "        trk.put(\"MAX_FRAME_GAP\", Integer.valueOf(max_frame_gap))\n",
    "        trk.put(\"LINKING_MAX_DISTANCE\", linking_max)\n",
    "        trk.put(\"GAP_CLOSING_MAX_DISTANCE\", gapclosing_max)\n",
    "        trk.put(\"ALLOW_TRACK_SPLITTING\", allow_split)\n",
    "        trk.put(\"ALLOW_TRACK_MERGING\", allow_merge)\n",
    "        settings.trackerSettings = trk\n",
    "\n",
    "        # Add all analyzers and optional track filters\n",
    "        settings.addAllAnalyzers()\n",
    "        if filter_displacement:\n",
    "            settings.addTrackFilter(FeatureFilter(\"TRACK_DISPLACEMENT\", displacement_cutoff, True))\n",
    "        if filter_duration:\n",
    "            settings.addTrackFilter(FeatureFilter(\"TRACK_DURATION\", duration_cutoff, True))\n",
    "\n",
    "        # Execute TrackMate\n",
    "        tm = TrackMate(model, settings)\n",
    "        if not tm.checkInput() or not tm.process():\n",
    "            print(\"  Error:\", tm.getErrorMessage())\n",
    "            imp.close()\n",
    "            continue\n",
    "\n",
    "        # Export tracking results to XML\n",
    "        xml_path = out_dir / f\"{nd2.stem}_Tracks.xml\"\n",
    "        ExportTracksToXML.export(model, settings, File(str(xml_path)))\n",
    "        print(\"  XML saved:\", xml_path.name)\n",
    "\n",
    "        # Save the image stack as TIF\n",
    "        tiff_path = out_dir / f\"{nd2.stem}.tif\"\n",
    "        ij.IJ.saveAs(imp, \"Tiff\", str(tiff_path))\n",
    "\n",
    "        # Extract and save metadata from image if available\n",
    "        info_str = imp.getProperty(\"Info\")\n",
    "        if info_str:\n",
    "            meta_path = out_dir / f\"{nd2.stem}_metadata.txt\"\n",
    "            with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(str(info_str))\n",
    "            print(\"  Metadata saved:\", meta_path.name)\n",
    "        else:\n",
    "            print(\"  Warning: No metadata found.\")\n",
    "\n",
    "        imp.close()\n",
    "        out_xmls.append(xml_path)\n",
    "\n",
    "    return out_xmls\n",
    "\n",
    "def load_tracks_xml(filepath):\n",
    "    \"\"\"\n",
    "    Parse a TrackMate-generated XML file and extract tracking data.\n",
    "\n",
    "    Each <particle> element in the XML represents one individual track.\n",
    "    All detections (spots) within a track are read in their original order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str or Path\n",
    "        Path to the TrackMate XML file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tracks : list of pandas.DataFrame\n",
    "        A list of DataFrames, each corresponding to a single track.\n",
    "        Each DataFrame has columns: [\"T\", \"X\", \"Y\", \"Z\"], representing\n",
    "        time point and spatial coordinates of each detection.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the XML tree\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    tracks = []\n",
    "\n",
    "    # Find all <particle> elements (each representing a track)\n",
    "    particles = root.findall(\".//particle\")\n",
    "\n",
    "    for particle in particles:\n",
    "        # Extract all <detection> elements within each particle\n",
    "        detections = particle.findall(\".//detection\")\n",
    "        t_list = []\n",
    "\n",
    "        for d in detections:\n",
    "            # Extract time and spatial coordinates\n",
    "            t = float(d.attrib.get(\"t\", 0))\n",
    "            x = float(d.attrib.get(\"x\", 0))\n",
    "            y = float(d.attrib.get(\"y\", 0))\n",
    "            z = float(d.attrib.get(\"z\", 0))\n",
    "            t_list.append([t, x, y, z])\n",
    "\n",
    "        # Only add non-empty tracks\n",
    "        if len(t_list) > 0:\n",
    "            tracks.append(pd.DataFrame(t_list, columns=[\"T\", \"X\", \"Y\", \"Z\"]))\n",
    "\n",
    "    return tracks\n",
    "\n",
    "def compute_median_drift_from_tracks(tracks) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute median XY drift over time from multiple tracks.\n",
    "\n",
    "    Each track is aligned to its initial position, and then the median \n",
    "    displacement across all tracks is computed frame-by-frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tracks : list of pandas.DataFrame\n",
    "        A list of tracks returned from `load_tracks_xml()`.\n",
    "        Each DataFrame must contain columns [\"T\", \"X\", \"Y\", \"Z\"],\n",
    "        where T is the frame index, and X, Y, Z are spatial coordinates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    drift_trace : np.ndarray of shape (max_frame+1, 2)\n",
    "        An array containing median XY drift per frame.\n",
    "        Each row is [median_dx, median_dy] at that frame.\n",
    "    \"\"\"\n",
    "\n",
    "    if not tracks:\n",
    "        raise ValueError(\"Input track list is empty.\")\n",
    "\n",
    "    # Determine the maximum frame index across all tracks\n",
    "    max_frame = int(max(df[\"T\"].max() for df in tracks))\n",
    "\n",
    "    # Create padded arrays to store aligned X and Y positions\n",
    "    traj_x, traj_y = [], []\n",
    "\n",
    "    for df in tracks:\n",
    "        t = df[\"T\"].to_numpy(dtype=int)\n",
    "\n",
    "        # Normalize track positions so that the first point is treated as origin\n",
    "        x = df[\"X\"].to_numpy() - df[\"X\"].iloc[0]\n",
    "        y = df[\"Y\"].to_numpy() - df[\"Y\"].iloc[0]\n",
    "\n",
    "        # Initialize arrays with NaNs for full frame range\n",
    "        x_full = np.full(max_frame + 1, np.nan)\n",
    "        y_full = np.full(max_frame + 1, np.nan)\n",
    "\n",
    "        # Insert values at corresponding frame indices\n",
    "        x_full[t] = x\n",
    "        y_full[t] = y\n",
    "\n",
    "        traj_x.append(x_full)\n",
    "        traj_y.append(y_full)\n",
    "\n",
    "    # Stack all trajectories across tracks (frames × tracks)\n",
    "    traj_x = np.stack(traj_x, axis=1)\n",
    "    traj_y = np.stack(traj_y, axis=1)\n",
    "\n",
    "    # Compute median drift per frame, ignoring NaNs\n",
    "    median_x = np.nanmedian(traj_x, axis=1)\n",
    "    median_y = np.nanmedian(traj_y, axis=1)\n",
    "\n",
    "    # Return combined XY median drift as a (T, 2) array\n",
    "    return np.column_stack([median_x, median_y])\n",
    "\n",
    "def save_drift_trace_txt(trace_array, save_path):\n",
    "    \"\"\"\n",
    "    Save a drift trace array to a plain text file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace_array : np.ndarray\n",
    "        A 2D NumPy array of shape (T, 2), where each row represents\n",
    "        the median drift [dx, dy] at a specific frame.\n",
    "\n",
    "    save_path : str or Path\n",
    "        Path to the output text file. The file will be saved in plain text format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the array to a text file with 8 decimal precision\n",
    "    np.savetxt(save_path, trace_array, fmt='%.8f')\n",
    "\n",
    "def sanitize_description(desc: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove non-ASCII characters from a metadata string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    desc : str\n",
    "        Original metadata string that may contain non-ASCII characters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Sanitized ASCII-only string.\n",
    "    \"\"\"\n",
    "    return desc.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "def apply_drift_correction_to_tiff(input_tiff_path, drift_trace, output_prefix, n_channels=3, description_template=None):\n",
    "    \"\"\"\n",
    "    Apply frame-wise XY drift correction to a multi-channel 4D TIFF stack.\n",
    "\n",
    "    Each channel is independently corrected using FFT-based subpixel shifting,\n",
    "    and saved as a grayscale multipage TIFF image with photometric mode 'minisblack'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tiff_path : str or Path\n",
    "        Path to the input 4D TIFF image (shape: T, Y, X, C).\n",
    "\n",
    "    drift_trace : np.ndarray\n",
    "        Drift array of shape (T, 2), where each row is [dx, dy] for a frame.\n",
    "\n",
    "    output_prefix : str or Path\n",
    "        Prefix for the output file names. Each channel will be saved as:\n",
    "        <output_prefix>_chanX_drftc.tif\n",
    "\n",
    "    n_channels : int, default=3\n",
    "        Number of channels in the input image.\n",
    "\n",
    "    description_template : str, optional\n",
    "        Optional metadata string to be included in each output TIFF.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    input_path = Path(input_tiff_path)\n",
    "    stack = io.imread(input_path)  # Expected shape: (T, Y, X, C)\n",
    "\n",
    "    # Verify input shape is 4D\n",
    "    assert stack.ndim == 4, \"Input TIFF must be a 4D array (T, Y, X, C)\"\n",
    "    n_frames, height, width, n_chan_inferred = stack.shape\n",
    "    assert n_chan_inferred == n_channels, (\n",
    "        f\"Expected {n_channels} channels, but found {n_chan_inferred} in the image.\"\n",
    "    )\n",
    "\n",
    "    # Process each channel independently\n",
    "    for c in range(n_channels):\n",
    "        corrected_channel = np.empty((n_frames, height, width), dtype=np.uint16)\n",
    "\n",
    "        for t in range(n_frames):\n",
    "            # Get drift for the current frame (default to [0, 0] if trace is short)\n",
    "            dx, dy = drift_trace[t] if t < len(drift_trace) else (0, 0)\n",
    "\n",
    "            # Apply subpixel shift in frequency domain (note: [y, x] order for shift)\n",
    "            shifted = ifftn(fourier_shift(fftn(stack[t, :, :, c]), shift=[-dy, -dx])).real\n",
    "\n",
    "            # Clip values and convert to uint16\n",
    "            corrected_channel[t] = np.clip(np.round(shifted), 0, 65535).astype(np.uint16)\n",
    "\n",
    "        # Sanitize metadata string if provided\n",
    "        image_description = description_template\n",
    "        if image_description:\n",
    "            image_description = sanitize_description(image_description)\n",
    "\n",
    "        # Save corrected grayscale stack\n",
    "        output_path = Path(f\"{output_prefix}_chan{c+1}_drftc.tif\")\n",
    "        imwrite(\n",
    "            output_path,\n",
    "            corrected_channel,  # Shape: (T, Y, X)\n",
    "            photometric='minisblack',\n",
    "            description=image_description\n",
    "        )\n",
    "        print(f\"Drift-corrected grayscale saved → {output_path}\")\n",
    "\n",
    "def apply_chromatic_registration_from_mat(input_tiff_path, output_tiff_path, mat_path, description_template=None):\n",
    "    \"\"\"\n",
    "    Apply chromatic registration to a grayscale image stack using a 3x3 affine matrix from a MATLAB .mat file.\n",
    "\n",
    "    This function reads an affine transformation matrix stored under the key 'T' in a .mat file,\n",
    "    applies it to each frame of a TIFF image stack, and saves the registered result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tiff_path : str or Path\n",
    "        Path to the input grayscale multipage TIFF (shape: T, Y, X).\n",
    "\n",
    "    output_tiff_path : str or Path\n",
    "        Path where the registered image stack will be saved.\n",
    "\n",
    "    mat_path : str or Path\n",
    "        Path to the .mat file that contains the 3x3 affine matrix 'T'.\n",
    "\n",
    "    description_template : str, optional\n",
    "        Optional metadata string to be embedded into the TIFF.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    input_path = Path(input_tiff_path)\n",
    "    output_path = Path(output_tiff_path)\n",
    "    mat_path = Path(mat_path)\n",
    "\n",
    "    # Step 1: Load affine transformation matrix 'T' from .mat file\n",
    "    mat_data = loadmat(mat_path, simplify_cells=True)\n",
    "    if \"T\" not in mat_data:\n",
    "        raise KeyError(f\"Affine matrix 'T' not found in {mat_path.name}.\")\n",
    "    T = np.asarray(mat_data[\"T\"], dtype=np.float64).T  # Transpose to match ImageJ/MATLAB forward transform\n",
    "\n",
    "    # Step 2: Create an AffineTransform object\n",
    "    tform = AffineTransform(matrix=T)  # Forward transform (as in MATLAB)\n",
    "\n",
    "    # Step 3: Load image stack\n",
    "    stack = io.imread(str(input_path))  # Expected shape: (T, Y, X)\n",
    "    assert stack.ndim == 3, \"Input TIFF must have shape (frames, height, width).\"\n",
    "    n_frames, height, width = stack.shape\n",
    "    registered = np.empty_like(stack)\n",
    "\n",
    "    # Step 4: Apply the affine transform to each frame\n",
    "    for i in range(n_frames):\n",
    "        registered[i] = warp(\n",
    "            stack[i],\n",
    "            inverse_map=tform.inverse,  # Use inverse map to achieve forward transform effect\n",
    "            order=1,                    # Bilinear interpolation (default in MATLAB)\n",
    "            preserve_range=True,\n",
    "            output_shape=(height, width)\n",
    "        ).astype(stack.dtype)\n",
    "\n",
    "    # Step 5: Sanitize and apply metadata if provided\n",
    "    image_description = description_template\n",
    "    if image_description:\n",
    "        image_description = sanitize_description(image_description)\n",
    "\n",
    "    # Step 6: Save the registered stack as grayscale TIFF\n",
    "    imwrite(\n",
    "        output_path,\n",
    "        registered,  # shape: (T, Y, X)\n",
    "        photometric='minisblack',\n",
    "        description=image_description\n",
    "    )\n",
    "\n",
    "    print(f\"Chromatic-registered stack saved → {output_path}\")\n",
    "\n",
    "def combine_tif_channels(\n",
    "    root: str | Path,\n",
    "    *,\n",
    "    n_chan: int,\n",
    "    ij,\n",
    "    postfix: str = \"_drftc\",\n",
    "    delete_intermediate: bool = True,\n",
    "    description_template: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine individual single-channel TIFF stacks into a single multichannel TIFF.\n",
    "\n",
    "    This function loads grayscale image stacks for each channel and merges them\n",
    "    using ImageJ's \"Merge Channels...\" function. The merged result is saved as\n",
    "    a multichannel hyperstack TIFF with optional metadata embedding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str or Path\n",
    "        Directory containing the single-channel TIFF files.\n",
    "\n",
    "    n_chan : int\n",
    "        Number of channels to merge (currently supports 3 or 4).\n",
    "\n",
    "    ij : imagej.ImageJ\n",
    "        An initialized ImageJ instance (from pyimagej).\n",
    "\n",
    "    postfix : str, default=\"_drftc\"\n",
    "        Common suffix used in the filenames for channel images.\n",
    "\n",
    "    delete_intermediate : bool, default=True\n",
    "        Whether to delete the original single-channel TIFF files after merging.\n",
    "\n",
    "    description_template : str or None, optional\n",
    "        Optional metadata string to be embedded into the final TIFF file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_path : Path\n",
    "        Path to the final merged TIFF file.\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    assert n_chan in (3, 4), \"Only 3-channel or 4-channel merging is supported.\"\n",
    "\n",
    "    # Find base filenames to merge (those with channel 1 files)\n",
    "    pattern = re.compile(rf\"(.+)_chan1{postfix}\\.tif$\")\n",
    "    groups = [m.group(1) for m in map(pattern.match, os.listdir(root)) if m]\n",
    "    if not groups:\n",
    "        print(\"No matching TIFFs found for merging.\")\n",
    "        return\n",
    "\n",
    "    print(f\"> Found {len(groups)} merge targets with {n_chan} channels each.\")\n",
    "\n",
    "    # Define lookup table (LUT) order for color assignment\n",
    "    lut_order_dict = {\n",
    "        3: [\"Grays\", \"Green\", \"Red\"],\n",
    "        4: [\"Grays\", \"Blue\", \"Green\", \"Red\"]\n",
    "    }\n",
    "\n",
    "    for base in groups:\n",
    "        filenames = [f\"{base}_chan{c}{postfix}.tif\" for c in range(1, n_chan + 1)]\n",
    "        filenames2delete = filenames.copy()\n",
    "        save_name = f\"{base}{postfix}_reg.tif\"\n",
    "\n",
    "        # Close all ImageJ windows before starting merge\n",
    "        ij.IJ.run(\"Close All\")\n",
    "        imps = []\n",
    "\n",
    "        # Open each channel TIFF and register window\n",
    "        for f in filenames:\n",
    "            imp = ij.IJ.openImage(str(root / f))\n",
    "            if imp is None:\n",
    "                raise FileNotFoundError(f\"File not found: {f}\")\n",
    "            imp.show()\n",
    "            imps.append(imp)\n",
    "\n",
    "        titles = ij.WindowManager.getImageTitles()\n",
    "\n",
    "        # Merge channels using ImageJ GUI command\n",
    "        merge_args = \" \".join([f\"c{i+1}={titles[i]}\" for i in range(n_chan)]) + \" create\"\n",
    "        ij.IJ.run(\"Merge Channels...\", merge_args)\n",
    "        comp = ij.IJ.getImage()\n",
    "\n",
    "        # Assign LUTs (color maps) to each channel\n",
    "        for idx, lut in enumerate(lut_order_dict[n_chan], start=1):\n",
    "            comp.setPosition(idx)\n",
    "            ij.IJ.run(comp, lut, \"\")\n",
    "\n",
    "        # Correct dimensional metadata if necessary (swap Z and T)\n",
    "        dims = comp.getDimensions()  # Returns [X, Y, C, Z, T]\n",
    "        if dims[3] > 1 and dims[4] == 1:\n",
    "            comp.setDimensions(dims[2], dims[4], dims[3])  # C, T, Z order\n",
    "\n",
    "        # Extract original metadata from the first channel image\n",
    "        first_channel_path = root / filenames[0]\n",
    "        ref_img = ij.IJ.openImage(str(first_channel_path))\n",
    "        info = ref_img.getProperty(\"Info\")\n",
    "        ref_img.close()\n",
    "\n",
    "        if info is None:\n",
    "            raise ValueError(f\"Metadata 'Info' not found in: {first_channel_path}\")\n",
    "        info_str = str(info)\n",
    "\n",
    "        # Extract number of frames and time interval from metadata\n",
    "        match_frames = re.search(r\"SizeT\\s*=\\s*(\\d+)\", info_str)\n",
    "        match_interval = re.search(r\"finterval\\s*=\\s*([\\d\\.]+)\", info_str)\n",
    "\n",
    "        if not match_frames:\n",
    "            raise ValueError(\"'SizeT' (number of frames) not found in metadata.\")\n",
    "\n",
    "        frames = match_frames.group(1)\n",
    "        finter = match_interval.group(1) if match_interval else \"1.0\"  # Default to 1.0 sec\n",
    "        ij.IJ.run(\"Properties...\", f\"channels={n_chan} slices=1 frames={frames} interval={finter}\")\n",
    "\n",
    "        # Apply metadata (ImageDescription)\n",
    "        image_description = description_template\n",
    "        if image_description:\n",
    "            image_description = sanitize_description(image_description)\n",
    "            comp.setProperty(\"Info\", image_description)\n",
    "\n",
    "        # Save the merged image\n",
    "        out_path = root / save_name\n",
    "        ij.IJ.saveAs(comp, \"Tiff\", str(out_path))\n",
    "        comp.close()\n",
    "        print(f\"Saved merged TIFF → {out_path.name}\")\n",
    "\n",
    "        # Optionally delete intermediate single-channel files\n",
    "        if delete_intermediate:\n",
    "            for f in filenames2delete:\n",
    "                (root / f).unlink(missing_ok=True)\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_precorrection(nd2_path, config, mat_path, ij):\n",
    "    \"\"\"\n",
    "    Run the full drift and chromatic correction pipeline on a multichannel ND2 image.\n",
    "\n",
    "    This function performs:\n",
    "    1. Spot detection and tracking using TrackMate\n",
    "    2. Drift estimation from tracking results\n",
    "    3. Frame-wise XY drift correction across all channels\n",
    "    4. Chromatic registration using a MATLAB-generated affine transform\n",
    "    5. Final multichannel TIFF reconstruction and export\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nd2_path : str\n",
    "        Path to the input ND2 image file.\n",
    "\n",
    "    config : dict\n",
    "        Dictionary containing all TrackMate and processing parameters.\n",
    "\n",
    "    mat_path : str or Path\n",
    "        Path to the .mat file containing the 3x3 chromatic affine matrix ('T').\n",
    "\n",
    "    ij : imagej.ImageJ\n",
    "        Initialized ImageJ instance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tif_path : Path\n",
    "        Path to the final drift- and chromatic-corrected multichannel TIFF.\n",
    "    \"\"\"\n",
    "\n",
    "    # [0] Prepare output directories and names\n",
    "    base_dir = os.path.abspath(os.path.join(os.path.dirname(nd2_path), os.pardir))\n",
    "    track_dir = os.path.join(base_dir, \"2.Tracks_for_driftc\")\n",
    "    reg_dir = os.path.join(base_dir, \"3.driftc_reg\")\n",
    "    os.makedirs(track_dir, exist_ok=True)\n",
    "    os.makedirs(reg_dir, exist_ok=True)\n",
    "\n",
    "    filename_head = os.path.splitext(os.path.basename(nd2_path))[0]\n",
    "    n_chan = config[\"n_channels\"]\n",
    "    target_reg_chan = config[\"target_registration_chan\"]\n",
    "\n",
    "    # [1] Run tracking using TrackMate with given config\n",
    "    print(\"[1] Tracking and filtering...\")\n",
    "    xml_path = run_trackmate_nd2(\n",
    "        nd2_path,\n",
    "        track_dir,\n",
    "        target_chan=config[\"target_chan\"],\n",
    "        spot_radius=config[\"spot_radius\"],\n",
    "        threshold=config[\"threshold\"],\n",
    "        subpixel=config[\"subpixel\"],\n",
    "        median_filter=config[\"median_filter\"],\n",
    "        linking_max=config[\"linking_max\"],\n",
    "        gapclosing_max=config[\"gapclosing_max\"],\n",
    "        max_frame_gap=config[\"max_frame_gap\"],\n",
    "        allow_split=config[\"allow_split\"],\n",
    "        allow_merge=config[\"allow_merge\"],\n",
    "        filter_quality=config[\"filter_quality\"],\n",
    "        quality_cutoff=config[\"quality_cutoff\"],\n",
    "        filter_displacement=config[\"filter_displacement\"],\n",
    "        displacement_cutoff=config[\"displacement_cutoff\"],\n",
    "        filter_duration=config[\"filter_duration\"],\n",
    "        duration_cutoff_time=config[\"duration_cutoff_time\"]\n",
    "    )\n",
    "\n",
    "    # Load tracking data from XML\n",
    "    df_list = load_tracks_xml(str(xml_path[0]))\n",
    "\n",
    "    # [2] Compute and save drift trace from tracking results\n",
    "    print(\"[2] Drift trace generation...\")\n",
    "    drift_trace = compute_median_drift_from_tracks(df_list)\n",
    "    drift_txt_path = os.path.join(track_dir, f\"{filename_head}_drift.txt\")\n",
    "    save_drift_trace_txt(drift_trace, drift_txt_path)\n",
    "\n",
    "    # [3] Apply drift correction to all channels\n",
    "    print(\"[3] Drift correction...\")\n",
    "    description_path = os.path.join(track_dir, f\"{filename_head}_metadata.txt\")\n",
    "    description_template = None\n",
    "    if os.path.exists(description_path):\n",
    "        with open(description_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            description_template = f.read()\n",
    "\n",
    "    raw_stack_path = os.path.join(track_dir, f\"{filename_head}.tif\")\n",
    "    corrected_prefix = os.path.join(reg_dir, filename_head)\n",
    "    apply_drift_correction_to_tiff(\n",
    "        input_tiff_path=raw_stack_path,\n",
    "        drift_trace=drift_trace,\n",
    "        output_prefix=corrected_prefix,\n",
    "        n_channels=n_chan,\n",
    "        description_template=description_template\n",
    "    )\n",
    "\n",
    "    # [4] Apply chromatic registration using the affine matrix from MATLAB\n",
    "    print(\"[4] Chromatic error correction...\")\n",
    "    apply_chromatic_registration_from_mat(\n",
    "        os.path.join(reg_dir, f\"{filename_head}_chan{target_reg_chan}_drftc.tif\"),\n",
    "        os.path.join(reg_dir, f\"{filename_head}_chan{target_reg_chan}_drftc.tif\"),\n",
    "        mat_path,\n",
    "        description_template=description_template\n",
    "    )\n",
    "\n",
    "    # [5] Merge corrected channels into final multichannel TIFF using ImageJ\n",
    "    print(\"[5] Merging channels to multichannel TIF...\")\n",
    "    tif_path = combine_tif_channels(\n",
    "        reg_dir,\n",
    "        n_chan=n_chan,\n",
    "        ij=ij,\n",
    "        postfix=\"_drftc\",\n",
    "        delete_intermediate=True,\n",
    "        description_template=description_template\n",
    "    )\n",
    "\n",
    "    print(\"Full pipeline completed.\")\n",
    "\n",
    "    return tif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada52356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_paths_for_g_r_tracks(tif_path: str | Path) -> tuple[Path, Path, Path]:\n",
    "    \"\"\"\n",
    "    Derive output paths for green and red channel tracking results based on the TIFF file path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tif_path : str or Path\n",
    "        Path to the registered TIFF file (typically ending with '_drftc_reg.tif').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delay_dir : Path\n",
    "        Path to the output directory (4.Tracks_for_TimeDelay).\n",
    "\n",
    "    xml_g_path : Path\n",
    "        Output path for TrackMate result XML of the green channel.\n",
    "\n",
    "    xml_r_path : Path\n",
    "        Output path for TrackMate result XML of the red channel.\n",
    "    \"\"\"\n",
    "    tif_path = Path(tif_path)\n",
    "    parent_dir = tif_path.parent.parent  # Navigate two levels up to reach base directory\n",
    "    delay_dir = parent_dir / \"4.Tracks_for_TimeDelay\"\n",
    "    delay_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    filename_head = tif_path.stem.replace(\"_drftc_reg\", \"\")\n",
    "    xml_g_path = delay_dir / f\"{filename_head}_drftc_reg_g.xml\"\n",
    "    xml_r_path = delay_dir / f\"{filename_head}_drftc_reg_r.xml\"\n",
    "\n",
    "    return delay_dir, xml_g_path, xml_r_path\n",
    "\n",
    "def run_trackmate_dual_channel_from_config(ij, tif_path, config_green, config_red):\n",
    "    \"\"\"\n",
    "    Run TrackMate analysis independently on green and red channels of a multichannel TIFF,\n",
    "    and export the tracking results as XML files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ij : imagej.ImageJ\n",
    "        An initialized ImageJ instance (from pyimagej).\n",
    "\n",
    "    tif_path : str or Path\n",
    "        Path to the input multichannel TIFF file (e.g., with '_drftc_reg' suffix).\n",
    "\n",
    "    config_green : dict\n",
    "        Configuration dictionary for green channel tracking parameters.\n",
    "\n",
    "    config_red : dict\n",
    "        Configuration dictionary for red channel tracking parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    tif_path = Path(tif_path)\n",
    "    base_dir = tif_path.parent.parent\n",
    "    output_dir = base_dir / \"4.Tracks_for_TimeDelay\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    base_name = tif_path.stem.replace(\"_drftc_reg\", \"\")\n",
    "    xml_g_path = output_dir / f\"{base_name}_drftc_reg_g.xml\"\n",
    "    xml_r_path = output_dir / f\"{base_name}_drftc_reg_r.xml\"\n",
    "\n",
    "    # Load image in ImageJ\n",
    "    imp = ij.IJ.openImage(str(tif_path))\n",
    "    if imp is None:\n",
    "        raise FileNotFoundError(f\"Cannot open image: {tif_path}\")\n",
    "    imp.show()\n",
    "\n",
    "    # Standardize calibration metadata\n",
    "    cal = imp.getCalibration()\n",
    "    cal.setUnit(\"pixels\")\n",
    "    cal.pixelWidth = cal.pixelHeight = cal.pixelDepth = 1.0\n",
    "    cal.setTimeUnit(\"sec\")\n",
    "    cal.frameInterval = 2.5\n",
    "    imp.setCalibration(cal)\n",
    "\n",
    "    # Correct dimension order if needed (e.g., Z/T swap)\n",
    "    dims = imp.getDimensions()\n",
    "    if len(dims) >= 5 and dims[3] > 1 and dims[4] == 1:\n",
    "        imp.setDimensions(dims[2], dims[4], dims[3])  # C, T, Z\n",
    "\n",
    "    def run_single_channel(config, xml_out_path):\n",
    "        \"\"\"\n",
    "        Run TrackMate on a single channel using the provided config,\n",
    "        and export the result to XML.\n",
    "        \"\"\"\n",
    "        model = Model()\n",
    "        model.setLogger(Logger.IJ_LOGGER)\n",
    "        model.setPhysicalUnits(cal.getUnit(), cal.getTimeUnit())\n",
    "\n",
    "        settings = Settings(imp)\n",
    "\n",
    "        # Set up detector\n",
    "        settings.detectorFactory = LogDetectorFactory()\n",
    "        det = HashMap()\n",
    "        det.put(\"DO_SUBPIXEL_LOCALIZATION\", config[\"subpixel\"])\n",
    "        det.put(\"RADIUS\", config[\"spot_radius\"])\n",
    "        det.put(\"TARGET_CHANNEL\", Integer(config[\"target_chan\"]))\n",
    "        det.put(\"THRESHOLD\", config[\"threshold\"])\n",
    "        det.put(\"DO_MEDIAN_FILTERING\", config[\"median_filter\"])\n",
    "        settings.detectorSettings = det\n",
    "\n",
    "        # Spot quality filter (optional)\n",
    "        if config.get(\"filter_quality\", True):\n",
    "            settings.addSpotFilter(\n",
    "                FeatureFilter(\"QUALITY\", config.get(\"quality_cutoff\", 0.0), True)\n",
    "            )\n",
    "\n",
    "        # Set up tracker\n",
    "        settings.trackerFactory = SparseLAPTrackerFactory()\n",
    "        trk = settings.trackerFactory.getDefaultSettings()\n",
    "        trk.put(\"MAX_FRAME_GAP\", Integer(config[\"max_frame_gap\"]))\n",
    "        trk.put(\"LINKING_MAX_DISTANCE\", config[\"linking_max\"])\n",
    "        trk.put(\"GAP_CLOSING_MAX_DISTANCE\", config[\"gapclosing_max\"])\n",
    "        trk.put(\"ALLOW_TRACK_SPLITTING\", config[\"allow_split\"])\n",
    "        trk.put(\"ALLOW_TRACK_MERGING\", config[\"allow_merge\"])\n",
    "        settings.trackerSettings = trk\n",
    "\n",
    "        # Compute duration cutoff\n",
    "        fi = cal.frameInterval\n",
    "        nT = imp.getDimensions()[4]\n",
    "        duration_cutoff = config[\"duration_cutoff_time\"]\n",
    "        if math.isnan(duration_cutoff):\n",
    "            duration_cutoff = fi * (nT - 1.5)\n",
    "\n",
    "        settings.addAllAnalyzers()\n",
    "\n",
    "        # Optional track filters\n",
    "        if config.get(\"filter_displacement\", True):\n",
    "            settings.addTrackFilter(\n",
    "                FeatureFilter(\"TRACK_DISPLACEMENT\", config[\"displacement_cutoff\"], True)\n",
    "            )\n",
    "\n",
    "        if config.get(\"filter_duration\", True):\n",
    "            settings.addTrackFilter(\n",
    "                FeatureFilter(\"TRACK_DURATION\", duration_cutoff, True)\n",
    "            )\n",
    "\n",
    "        if config.get(\"filter_track_start\", True):\n",
    "            settings.addTrackFilter(\n",
    "                FeatureFilter(\"TRACK_START\", config.get(\"track_start_time\", 1), True)\n",
    "            )\n",
    "\n",
    "        # Execute TrackMate\n",
    "        tm = TrackMate(model, settings)\n",
    "        if not tm.checkInput() or not tm.process():\n",
    "            raise RuntimeError(tm.getErrorMessage())\n",
    "\n",
    "        ExportTracksToXML.export(model, settings, File(str(xml_out_path)))\n",
    "        print(f\"TrackMate result saved → {xml_out_path.name}\")\n",
    "\n",
    "    # Run for green channel\n",
    "    print(\"TrackMate: Green channel...\")\n",
    "    run_single_channel(config_green, xml_g_path)\n",
    "\n",
    "    # Run for red channel\n",
    "    print(\"TrackMate: Red channel...\")\n",
    "    run_single_channel(config_red, xml_r_path)\n",
    "\n",
    "    imp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01722e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background_and_merge(tif_path, rolling=5, ij=ij):\n",
    "    \"\"\"\n",
    "    Subtract background from channel 2 and 3 of a multichannel TIFF using ImageJ,\n",
    "    then merge the corrected channels into a new 3-channel TIFF and save the result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tif_path : str or Path\n",
    "        Path to the original multichannel TIFF image.\n",
    "\n",
    "    rolling : int, default=5\n",
    "        Radius of the rolling ball for background subtraction (in pixels).\n",
    "\n",
    "    ij : imagej.ImageJ\n",
    "        An initialized ImageJ instance for executing macro operations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_path : Path\n",
    "        Path to the saved background-corrected and merged TIFF file.\n",
    "    \"\"\"\n",
    "    tif_path = Path(tif_path)\n",
    "    tif_name = tif_path.stem\n",
    "\n",
    "    # Create output directory\n",
    "    out_dir = tif_path.parent.parent / \"5.Background_Corrected\"\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    out_path = out_dir / f\"{tif_name}_back.tif\"\n",
    "\n",
    "    # Load the original multichannel TIFF\n",
    "    imp = ij.IJ.openImage(str(tif_path))\n",
    "    imp.show()\n",
    "\n",
    "    # Split the image into separate channels\n",
    "    ij.IJ.run(\"Split Channels\")\n",
    "\n",
    "    # Define expected window titles for each channel\n",
    "    c1_title = f\"C1-{tif_name}.tif\"\n",
    "    c2_title = f\"C2-{tif_name}.tif\"\n",
    "    c3_title = f\"C3-{tif_name}.tif\"\n",
    "\n",
    "    # Apply background subtraction to channel 2\n",
    "    ij.IJ.selectWindow(c2_title)\n",
    "    ij.IJ.run(\"Subtract Background...\", f\"rolling={rolling} stack\")\n",
    "\n",
    "    # Apply background subtraction to channel 3\n",
    "    ij.IJ.selectWindow(c3_title)\n",
    "    ij.IJ.run(\"Subtract Background...\", f\"rolling={rolling} stack\")\n",
    "\n",
    "    # Retrieve the channel image objects\n",
    "    c1 = WindowManager.getImage(c1_title)\n",
    "\n",
    "    # Ensure the correct images are selected for merging\n",
    "    ij.IJ.selectWindow(c2_title)\n",
    "    c2_corr = WindowManager.getCurrentImage()\n",
    "\n",
    "    ij.IJ.selectWindow(c3_title)\n",
    "    c3_corr = WindowManager.getCurrentImage()\n",
    "\n",
    "    # Rename channels for merging recognition\n",
    "    c1.setTitle(\"C1\")\n",
    "    c2_corr.setTitle(\"C2_corr\")\n",
    "    c3_corr.setTitle(\"C3_corr\")\n",
    "\n",
    "    # Merge corrected channels:\n",
    "    #   - C1 to Channel 1\n",
    "    #   - C2_corr to Channel 2\n",
    "    #   - C3_corr to Channel 4 (ImageJ convention, Channel 3 left empty)\n",
    "    ij.IJ.run(\"Merge Channels...\", \"c1=C1 c2=C2_corr c4=C3_corr create\")\n",
    "    merged = WindowManager.getCurrentImage()\n",
    "\n",
    "    # Set intensity range and reset display\n",
    "    ij.IJ.setMinAndMax(merged, 0, 65535)\n",
    "    merged.resetDisplayRange()\n",
    "\n",
    "    # Save the result as a new TIFF file\n",
    "    ij.IJ.saveAsTiff(merged, str(out_path))\n",
    "\n",
    "    # Clean up all open ImageJ windows\n",
    "    ij.IJ.run(\"Close All\")\n",
    "\n",
    "    print(f\"Saved background-corrected TIFF: {out_path}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51449325",
   "metadata": {},
   "source": [
    "## Final Execution: Full Preprocessing and Tracking Pipeline\n",
    "\n",
    "The following code executes the full preprocessing and analysis workflow for a multichannel ND2 file. This includes:\n",
    "\n",
    "1. Drift correction\n",
    "2. Chromatic registration\n",
    "3. Dual-channel TrackMate tracking\n",
    "4. Background subtraction and re-merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_path = run_precorrection(nd2_path, config, mat_path, ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trackmate_dual_channel_from_config(ij,\n",
    "                                       tif_path,\n",
    "                                       config_green,\n",
    "                                       config_red\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3710d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_path = subtract_background_and_merge(tif_path, ij=ij)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
